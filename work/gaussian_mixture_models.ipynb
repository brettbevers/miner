{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "from scipy.stats import norm\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.clustering import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Gaussian in Eigenbasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_pinv(m):\n",
    "  U,s,Vh = np.linalg.svd(m)\n",
    "  s_inv = np.diag(np.power(s,-1))\n",
    "  m_inv = np.matmul(np.matmul(np.transpose(Vh), s_inv), np.transpose(U))\n",
    "  return m_inv\n",
    "\n",
    "def shuffle(*dfs):\n",
    "  dataset = reduce(lambda a,b: np.append(a, b, axis=0), dfs)\n",
    "  # Generate the permutation index array.\n",
    "  permutation = np.random.permutation(dataset.shape[0])\n",
    "  # Shuffle dataset by giving the permutation in the square brackets.\n",
    "  shuffled = dataset[permutation]\n",
    "  return shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmm.gaussian_mixture_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenvalues must be real and positive.\n",
    "lamb1_1, lamb1_2, lamb1_3 = 0.25, 1.0, 4.0\n",
    "\n",
    "# covariance is a square matrix, diagonal in the eigenbasis\n",
    "cov1 = np.array([\n",
    "  [lamb1_1, 0, 0],\n",
    "  [0, lamb1_2, 0],\n",
    "  [0, 0, lamb1_3]\n",
    "])\n",
    "\n",
    "mu1 = np.array([2,0,0])\n",
    "\n",
    "# eigenvalues must be real and positive.\n",
    "lamb2_1, lamb2_2, lamb2_3 = 0.111111, 1.0, 9.0\n",
    "\n",
    "# covariance is a square matrix, diagonal in the eigenbasis\n",
    "cov2 = np.array([\n",
    "  [lamb2_1, 0, 0],\n",
    "  [0, lamb2_2, 0],\n",
    "  [0, 0, lamb2_3]\n",
    "])\n",
    "\n",
    "mu2 = np.array([0,0,2])\n",
    "\n",
    "# eigenvalues must be real and positive.\n",
    "lamb3_1, lamb3_2, lamb3_3 = 0.33, 0.5, 3.0\n",
    "\n",
    "# covariance is a square matrix, diagonal in the eigenbasis\n",
    "cov3 = np.array([\n",
    "  [lamb3_1, 0, 0],\n",
    "  [0, lamb3_2, 0],\n",
    "  [0, 0, lamb3_3]\n",
    "])\n",
    "\n",
    "mu3 = np.array([0,2,0])\n",
    "\n",
    "# eigenvalues must be real and positive.\n",
    "lamb4_1, lamb4_2, lamb4_3 = 1.0, 2.0, 3.0\n",
    "\n",
    "# covariance is a square matrix, diagonal in the eigenbasis\n",
    "cov4 = np.array([\n",
    "  [lamb4_1, 0, 0],\n",
    "  [0, lamb4_2, 0],\n",
    "  [0, 0, lamb4_3]\n",
    "])\n",
    "\n",
    "mu4 = np.array([1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv1 = np.random.multivariate_normal(mu1, cov1, 25000)\n",
    "\n",
    "rv2 = np.random.multivariate_normal(mu2, cov2, 50000)\n",
    "\n",
    "rv3 = np.random.multivariate_normal(mu3, cov3, 50000)\n",
    "\n",
    "rv4 = np.random.multivariate_normal(mu4, cov4, 100000)\n",
    "\n",
    "independent_rvs = [norm(loc=-1.0, scale=0.5), norm(loc=0.0, scale=0.5), norm(loc=1.0, scale=0.5), norm(loc=2.0, scale=0.5)]\n",
    "\n",
    "error = norm(loc=0, scale=1)\n",
    "\n",
    "def gen_error():\n",
    "  return np.array([error.rvs(), error.rvs(), error.rvs()])\n",
    "\n",
    "data = sc.parallelize([ Vectors.dense(np.append(x + gen_error(), independent_rvs[np.random.randint(0,4)].rvs())) for x in shuffle(rv1, rv2, rv3, rv4) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gmm.gaussian_mixture_model' from '/usr/local/spark/python/gmm/gaussian_mixture_model.py'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(gmm.gaussian_mixture_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_service = gmm.gaussian_mixture_model.ModelingService(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1705510.79356 [-2414686.94360113 -2622025.48615185 -3447260.60294512 -2300763.72778414]\n"
     ]
    }
   ],
   "source": [
    "stats = modeling_service.get_stats(4, range(4))\n",
    "print(stats.log_likelihood, stats.p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-397280.64206182491"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = modeling_service.get_gmm(4,[0])\n",
    "m.log_likelihood(modeling_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-tuning using gain in log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1723816.10335661 -1747573.61591564 -1771145.70119122 -1836063.98274143\n -1732033.37785021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1717323.26246946 -1736159.09863704 -1760731.6902329  -1796214.69778217\n -1725543.57114666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1708273.86395669 -1728519.89911291 -1752688.87935763 -1787765.25047603\n -1719713.65675741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1706533.35247959 -1726828.06132709 -1750113.70107617 -1786175.64347773\n -1725114.70673793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1706011.7220369  -1720825.28024652 -1741035.35396039 -1785879.88761325\n -1725339.53707599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1706082.68663437 -1715871.1711803  -1741389.99941415 -1785697.86229021\n -1721345.32757171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1705940.54106405 -1724328.70622291 -1737042.71467506 -1776218.1951313\n -1722193.62831841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1705682.07881474 -1721515.1642646  -1740796.71936625 -1779473.67427251\n -1721668.05907534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1705674.24507534 -1722362.78743711 -1737962.38261963 -1766601.10673732\n -1722486.88601074]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "models = []\n",
    "results = []\n",
    "n = data.count()\n",
    "d = 4\n",
    "for i in range(1,10):\n",
    "  model = GaussianMixture.train(data, i)\n",
    "  models.append(model)\n",
    "  ll, p_values = log_likelihood_2(model, data)\n",
    "  p = float((d*(d+1)/2.0)*i + i)\n",
    "  bic = float(np.log(n)*p - 2*ll)\n",
    "  aic = float(2*p - 2*ll)\n",
    "  results.append(Row(k=i, ll=float(ll), bic=bic, aic=aic, p_values=[float(p) for p in p_values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 8.1402331507547386e-214, 1.0, 2.211169486216714e-52, 2.3904611078300201e-101, 0.33409984487413497]\n"
     ]
    }
   ],
   "source": [
    "p_values = [chi2.sf(-2*(results[i-1].ll - results[i].ll), df=d*(d+3)/2.0) for i in range(1, len(results))]\n",
    "print(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-6492.840887148166,\n -9049.398512767628,\n -1740.511477104621,\n -521.6304426859133,\n 70.9645974682644,\n -142.1455703151878,\n -258.462249313714,\n -7.833739404100925]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[results[i-1].ll - results[i].ll for i in range(1, len(results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-value estimate using Likelihood Ratio Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianMixture.train(data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_1(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_2(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "results = []\n",
    "d = 4\n",
    "for i in range(2,10):\n",
    "  model = GaussianMixture.train(data, 3)\n",
    "  ll, p_values = log_likelihood(model, data)\n",
    "  p = float((d*(d+1)/2.0)*i + i)\n",
    "  n = 45000.0\n",
    "  bic = float(np.log(n)*p - 2*ll)\n",
    "  aic = float(2*p - 2*ll)\n",
    "  results.append(Row(k=i, ll=float(ll), bic=bic, aic=aic, p_values=[float(p) for p in p_values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 4\n",
    "i, j = 0, 2\n",
    "\n",
    "chi2.sf(-2 * (results[i].ll - results[j].ll), df=(j-i)*(d*(d+3)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "name": "gaussian_mixture_models",
  "notebookId": 1154256.0
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
