{"cells":[{"cell_type":"markdown","source":["-sandbox\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["We are going to run all of the cells in the previous notebook to get our variables defined in this notebook."],"metadata":{}},{"cell_type":"code","source":["%run \"./00b Pandas Tutorial I\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["## Missing Data\n\npandas primarily uses the value np.nan to represent missing data. It is by default not included in computations. See the [Missing Data section](https://pandas.pydata.org/pandas-docs/version/0.23.0/missing_data.html#missing-data)\n\nReindexing allows you to change/add/delete the index on a specified axis. This returns a copy of the data."],"metadata":{}},{"cell_type":"code","source":["df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])\ndf1.loc[dates[0]:dates[1],'E'] = 1\ndf1"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["To drop any rows that have missing data."],"metadata":{}},{"cell_type":"code","source":["df1.dropna(how='any')"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["Filling missing data"],"metadata":{}},{"cell_type":"code","source":["df1.fillna(value=5)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["To get the boolean mask where values are nan (note: had to change `isna` to `isnull` because our version of pandas is different)."],"metadata":{}},{"cell_type":"code","source":["pd.isnull(df1)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["## Operations\n\nSee the Basic section on [Binary Ops](https://pandas.pydata.org/pandas-docs/version/0.23.0/basics.html#basics-binop)\n\nOperations in general exclude missing data."],"metadata":{}},{"cell_type":"markdown","source":["Performing a descriptive statistic"],"metadata":{}},{"cell_type":"code","source":["df.mean()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["Same operation on the other axis"],"metadata":{}},{"cell_type":"code","source":["df.mean(1)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Operating with objects that have different dimensionality and need alignment. In addition, pandas automatically broadcasts along the specified dimension."],"metadata":{}},{"cell_type":"code","source":["s = pd.Series([1,3,5,np.nan,6,8], index=dates).shift(2)\ns"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["df.sub(s, axis='index')"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["Applying functions to the data"],"metadata":{}},{"cell_type":"code","source":["df.apply(np.cumsum)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["df.apply(lambda x: x.max() - x.min())"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["Histogramming\n\nSee more at [Histogramming and Discretization](https://pandas.pydata.org/pandas-docs/version/0.23.0/basics.html#basics-discretization)"],"metadata":{}},{"cell_type":"code","source":["s = pd.Series(np.random.randint(0, 7, size=10))\ns"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["s.value_counts()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["String Methods\n\nSeries is equipped with a set of string processing methods in the str attribute that make it easy to operate on each element of the array, as in the code snippet below. Note that pattern-matching in str generally uses [regular expressions](https://docs.python.org/3/library/re.html) by default (and in some cases always uses them). See more at [Vectorized String Methods](https://pandas.pydata.org/pandas-docs/version/0.23.0/text.html#text-string-methods)."],"metadata":{}},{"cell_type":"code","source":["s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])\ns.str.lower()"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["## Merge\n\npandas provides various facilities for easily combining together Series, DataFrame, and Panel objects with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations.\n\nSee the [Merging section](https://pandas.pydata.org/pandas-docs/version/0.23.0/merging.html#merging)"],"metadata":{}},{"cell_type":"markdown","source":["Concatenating pandas objects together with [concat()](https://pandas.pydata.org/pandas-docs/version/0.23.0/generated/pandas.concat.html#pandas.concat)"],"metadata":{}},{"cell_type":"code","source":["df = pd.DataFrame(np.random.randn(10, 4))\ndf"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["# break it into pieces\npieces = [df[:3], df[3:7], df[7:]]\npd.concat(pieces)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["Join\n\nSQL style merges. See the [Database style joining](https://pandas.pydata.org/pandas-docs/version/0.23.0/merging.html#merging-join)"],"metadata":{}},{"cell_type":"code","source":["left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})\nleft"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})\nright"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["pd.merge(left, right, on='key')"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["Append rows to a dataframe. See the [Appending](https://pandas.pydata.org/pandas-docs/version/0.23.0/merging.html#merging-concatenation) section."],"metadata":{}},{"cell_type":"code","source":["df = pd.DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])\ndf"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["s = df.iloc[3]\ndf.append(s, ignore_index=True)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":["## Grouping\n\nBy “group by” we are referring to a process involving one or more of the following steps\n\n* Splitting the data into groups based on some criteria\n* Applying a function to each group independently\n* Combining the results into a data structure\n\nSee the [Grouping section](https://pandas.pydata.org/pandas-docs/version/0.23.0/groupby.html#groupby)"],"metadata":{}},{"cell_type":"code","source":["df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n                          'foo', 'bar', 'foo', 'foo'],\n                   'B' : ['one', 'one', 'two', 'three',\n                          'two', 'two', 'one', 'three'],\n                   'C' : np.random.randn(8),\n                   'D' : np.random.randn(8)})\n\ndf"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["Grouping and then applying the [sum()](https://pandas.pydata.org/pandas-docs/version/0.23.0/generated/pandas.DataFrame.sum.html#pandas.DataFrame.sum) function to the resulting groups."],"metadata":{}},{"cell_type":"code","source":["df.groupby('A').sum()"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":["Grouping by multiple columns forms a hierarchical index, and again we can apply the sum function."],"metadata":{}},{"cell_type":"code","source":["df.groupby(['A','B']).sum()"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":["## Reshaping\n\nSee the sections on [Hierarchical Indexing](https://pandas.pydata.org/pandas-docs/version/0.23.0/advanced.html#advanced-hierarchical) and [Reshaping](https://pandas.pydata.org/pandas-docs/version/0.23.0/reshaping.html#reshaping-stacking)."],"metadata":{}},{"cell_type":"code","source":["tuples = list(zip(*[['bar', 'bar', 'baz', 'baz',\n                     'foo', 'foo', 'qux', 'qux'],\n                    ['one', 'two', 'one', 'two',\n                     'one', 'two', 'one', 'two']]))\n\nindex = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\ndf = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])\ndf2 = df[:4]\ndf2"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":["The [stack()](https://pandas.pydata.org/pandas-docs/version/0.23.0/generated/pandas.DataFrame.stack.html#pandas.DataFrame.stack) method “compresses” a level in the DataFrame’s columns."],"metadata":{}},{"cell_type":"code","source":["stacked = df2.stack()\nstacked"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":["With a “stacked” DataFrame or Series (having a MultiIndex as the index), the inverse operation of [stack()](https://pandas.pydata.org/pandas-docs/version/0.23.0/generated/pandas.DataFrame.stack.html#pandas.DataFrame.stack) is [unstack()](https://pandas.pydata.org/pandas-docs/version/0.23.0/generated/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack), which by default unstacks the last level:"],"metadata":{}},{"cell_type":"code","source":["stacked.unstack()"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["stacked.unstack(1)"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["stacked.unstack(0)"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":["See the section on [Pivot Tables](https://pandas.pydata.org/pandas-docs/version/0.23.0/reshaping.html#reshaping-pivot)."],"metadata":{}},{"cell_type":"code","source":["df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three'] * 3,\n                   'B' : ['A', 'B', 'C'] * 4,\n                   'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n                   'D' : np.random.randn(12),\n                   'E' : np.random.randn(12)})\n\ndf"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"markdown","source":["We can produce pivot tables from this data very easily:"],"metadata":{}},{"cell_type":"code","source":["pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":["## Time Series\n\npandas has simple, powerful, and efficient functionality for performing resampling operations during frequency conversion (e.g., converting secondly data into 5-minutely data). This is extremely common in, but not limited to, financial applications. See the [Time Series section](https://pandas.pydata.org/pandas-docs/version/0.23.0/timeseries.html#timeseries)."],"metadata":{}},{"cell_type":"code","source":["rng = pd.date_range('1/1/2012', periods=100, freq='S')\nts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\nts.resample('5Min').sum()"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":["Time zone representation:"],"metadata":{}},{"cell_type":"code","source":["rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')\nts = pd.Series(np.random.randn(len(rng)), rng)\nts"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":["ts_utc = ts.tz_localize('UTC')\nts_utc"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":["Converting to another time zone:"],"metadata":{}},{"cell_type":"code","source":["ts_utc.tz_convert('US/Eastern')"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":["Converting between time span representations:"],"metadata":{}},{"cell_type":"code","source":["rng = pd.date_range('1/1/2012', periods=5, freq='M')\nts = pd.Series(np.random.randn(len(rng)), index=rng)\nts"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["ps = ts.to_period()\nps"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["ps.to_timestamp()"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"markdown","source":["Converting between period and timestamp enables some convenient arithmetic functions to be used. In the following example, we convert a quarterly frequency with year ending in November to 9am of the end of the month following the quarter end:"],"metadata":{}},{"cell_type":"code","source":["prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')\nts = pd.Series(np.random.randn(len(prng)), prng)\nts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9\nts.head()"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"markdown","source":["## Categoricals\n\npandas can include categorical data in a DataFrame. For full docs, see the [categorical introduction](https://pandas.pydata.org/pandas-docs/version/0.23.0/categorical.html#categorical) and the [API documentation](https://pandas.pydata.org/pandas-docs/version/0.23.0/api.html#api-categorical)."],"metadata":{}},{"cell_type":"code","source":["df = pd.DataFrame({\"id\":[1,2,3,4,5,6], \"raw_grade\":['a', 'b', 'b', 'a', 'a', 'e']})"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":["Convert the raw grades to a categorical data type."],"metadata":{}},{"cell_type":"code","source":["df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\ndf[\"grade\"]"],"metadata":{},"outputs":[],"execution_count":73},{"cell_type":"markdown","source":["Rename the categories to more meaningful names (assigning to Series.cat.categories is inplace!)."],"metadata":{}},{"cell_type":"code","source":["df[\"grade\"].cat.categories = [\"very good\", \"good\", \"very bad\"]"],"metadata":{},"outputs":[],"execution_count":75},{"cell_type":"markdown","source":["Reorder the categories and simultaneously add the missing categories (methods under Series .cat return a new Series by default)."],"metadata":{}},{"cell_type":"code","source":["df[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\", \"medium\", \"good\", \"very good\"])\ndf[\"grade\"]"],"metadata":{},"outputs":[],"execution_count":77},{"cell_type":"markdown","source":["Sorting is per order in the categories, not lexical order."],"metadata":{}},{"cell_type":"code","source":["df.sort_values(by=\"grade\")"],"metadata":{},"outputs":[],"execution_count":79},{"cell_type":"markdown","source":["Grouping by a categorical column also shows empty categories."],"metadata":{}},{"cell_type":"code","source":["df.groupby(\"grade\").size()"],"metadata":{},"outputs":[],"execution_count":81},{"cell_type":"markdown","source":["## Plotting\n\nSee the [Plotting](https://pandas.pydata.org/pandas-docs/version/0.23.0/visualization.html#visualization) docs."],"metadata":{}},{"cell_type":"code","source":["ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\nts = ts.cumsum()\nfig = ts.plot()\ndisplay(fig.figure) # Need to wrap in display for Databricks"],"metadata":{},"outputs":[],"execution_count":83},{"cell_type":"markdown","source":["On a DataFrame, the [plot()](https://pandas.pydata.org/pandas-docs/version/0.23.0/generated/pandas.DataFrame.plot.html#pandas.DataFrame.plot) method is a convenience to plot all of the columns with labels:"],"metadata":{}},{"cell_type":"code","source":["df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=['A', 'B', 'C', 'D'])\ndf = df.cumsum()\nplt.figure(); df.plot(); plt.legend(loc='best')\ndisplay(plt.show())"],"metadata":{},"outputs":[],"execution_count":85},{"cell_type":"markdown","source":["## Getting Data In/Out"],"metadata":{}},{"cell_type":"markdown","source":["[Writing to a csv file.](https://pandas.pydata.org/pandas-docs/version/0.23.0/io.html#io-store-in-csv)"],"metadata":{}},{"cell_type":"code","source":["df.to_csv('foo.csv')"],"metadata":{},"outputs":[],"execution_count":88},{"cell_type":"markdown","source":["[Reading from a csv file.](https://pandas.pydata.org/pandas-docs/version/0.23.0/io.html#io-read-csv-table)"],"metadata":{}},{"cell_type":"code","source":["pd.read_csv('foo.csv')"],"metadata":{},"outputs":[],"execution_count":90},{"cell_type":"markdown","source":["HDF5\n\nReading and writing to [HDFStores](https://pandas.pydata.org/pandas-docs/stable/io.html#io-hdf5).\n\nWriting to a HDF5 Store."],"metadata":{}},{"cell_type":"code","source":["%sh /databricks/python/bin/pip install tables\n/databricks/python/bin/pip install xlrd"],"metadata":{},"outputs":[],"execution_count":92},{"cell_type":"code","source":["df.to_hdf('foo.h5','df')"],"metadata":{},"outputs":[],"execution_count":93},{"cell_type":"markdown","source":["Reading from a HDF5 Store."],"metadata":{}},{"cell_type":"code","source":["pd.read_hdf('foo.h5','df')"],"metadata":{},"outputs":[],"execution_count":95},{"cell_type":"markdown","source":["Excel\n\nReading and writing to [MS Excel](https://pandas.pydata.org/pandas-docs/version/0.23.0/io.html#io-excel).\n\nWriting to an excel file."],"metadata":{}},{"cell_type":"code","source":["df.to_excel('foo.xlsx', sheet_name='Sheet1')"],"metadata":{},"outputs":[],"execution_count":97},{"cell_type":"markdown","source":["Reading from an excel file."],"metadata":{}},{"cell_type":"code","source":["pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])"],"metadata":{},"outputs":[],"execution_count":99},{"cell_type":"markdown","source":["## Gotchas\n\nIf you are attempting to perform an operation you might see an exception like:"],"metadata":{}},{"cell_type":"code","source":["if pd.Series([False, True, False]):\n    print(\"I was true\")"],"metadata":{},"outputs":[],"execution_count":101},{"cell_type":"markdown","source":["See [Comparisons](https://pandas.pydata.org/pandas-docs/version/0.23.0/basics.html#basics-compare) for an explanation and what to do.\n\nSee [Gotchas](https://pandas.pydata.org/pandas-docs/version/0.23.0/gotchas.html#gotchas) as well."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2018 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"00c Pandas Tutorial II","notebookId":1256911},"nbformat":4,"nbformat_minor":0}
