{"cells":[{"cell_type":"markdown","source":["-sandbox\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["## Intro to Neural Networks with Keras II\n\nIn this notebook, we will build upon the concepts introduce the in previous lab to build a neural network that is more powerful than a simple linear regression model!\n\nWe will use the California Housing Dataset.\n\nObjectives:\n   * Activation Functions\n   * Loss functions\n   * Optimizer\n   * Batch Size"],"metadata":{}},{"cell_type":"code","source":["from sklearn.datasets.california_housing import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nnp.random.seed(0)\n\ncal_housing = fetch_california_housing()\n\n# split 80/20 train-test\nX_train, X_test, y_train, y_test = train_test_split(cal_housing.data,\n                                                        cal_housing.target,\n                                                        test_size=0.2,\n                                                        random_state=1)\n\nprint(cal_housing.DESCR)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">downloading Cal. housing from http://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.tgz to /root/scikit_learn_data\nCalifornia housing dataset.\n\nThe original database is available from StatLib\n\n    http://lib.stat.cmu.edu/\n\nThe data contains 20,640 observations on 9 variables.\n\nThis dataset contains the average house value as target variable\nand the following input variables (features): average income,\nhousing average age, average rooms, average bedrooms, population,\naverage occupation, latitude, and longitude in that order.\n\nReferences\n----------\n\nPace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\nStatistics and Probability Letters, 33 (1997) 291-297.\n\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["X_train.shape"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">11</span><span class=\"ansired\">]: </span>(16512, 8)\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["# Recall from Last Lab\n![Life Cycle](https://brookewenig.github.io/img/DL/Life-Cycle-for-Neural-Network-Models-in-Keras.png)"],"metadata":{}},{"cell_type":"markdown","source":["## Define a Network\n\nLet's not just reinvent linear regression. Let's build a model, but with multiple layers using the [Sequential model](https://keras.io/getting-started/sequential-model-guide/) from Keras.\n\n![](https://brookewenig.github.io/img/DL/NN-Regression.jpg)"],"metadata":{}},{"cell_type":"markdown","source":["## 1. Activation Function\n\nIf we keep the activation as linear, then we aren't utilizing the power of neural networks!! The power of neural networks derives from the non-linear combinations of linear functions.\n\n**RECAP:** So what are our options for [activation functions](http://cs231n.github.io/neural-networks-1/#actfun)?"],"metadata":{}},{"cell_type":"code","source":["import tensorflow as tf\ntf.set_random_seed(42) # For reproducibility\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel = Sequential()\n\n# Input layer\nmodel.add(Dense(20, input_dim=8, activation='relu')) \n\n# Automatically infers the input_dim based on the layer before it\nmodel.add(Dense(20, activation='relu')) \n\n# Output layer\nmodel.add(Dense(1, activation='linear')) "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from &#96;float&#96; to &#96;np.floating&#96; is deprecated. In future, it will be treated as &#96;np.float64 == np.dtype(float).type&#96;.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["#### Alternative Keras Model Syntax"],"metadata":{}},{"cell_type":"code","source":["def build_model():\n  return Sequential([Dense(20, input_dim=8, activation='relu'),\n                    Dense(20, activation='relu'),\n                    Dense(1, activation='linear')]) # Keep the last layer as linear because this is a regression problem"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["We can check the model definition by calling `.summary()`"],"metadata":{}},{"cell_type":"code","source":["model = build_model()\nmodel.summary()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_4 (Dense)              (None, 20)                180       \n_________________________________________________________________\ndense_5 (Dense)              (None, 20)                420       \n_________________________________________________________________\ndense_6 (Dense)              (None, 1)                 21        \n=================================================================\nTotal params: 621\nTrainable params: 621\nNon-trainable params: 0\n_________________________________________________________________\n</div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["## 2. Loss Functions + Metrics\n\nIn Keras, the *loss function* is the function for our optimizer to minimize. *[Metrics](https://keras.io/metrics/)* are similar to a loss function, except that the results from evaluating a metric are not used when training the model.\n\n**Recap:** Which loss functions should we use for regression? Classification?"],"metadata":{}},{"cell_type":"code","source":["from keras import metrics\nfrom keras import losses\n\nloss = \"mse\" # Or loss = losses.mse\nmetrics = [\"mae\", \"mse\"] # Or metrics = [metrics.mae, metrics.mse]\n\nmodel.compile(optimizer=\"sgd\", loss=loss, metrics=metrics)\nmodel.fit(X_train, y_train, epochs=10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Epoch 1/10\n\n   32/16512 [..............................] - ETA: 1:04 - loss: 66603.5156 - mean_absolute_error: 220.5282 - mean_squared_error: 66603.5156\n 1248/16512 [=&gt;............................] - ETA: 2s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan                     \n 2368/16512 [===&gt;..........................] - ETA: 1s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 3552/16512 [=====&gt;........................] - ETA: 1s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 4800/16512 [=======&gt;......................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 6016/16512 [=========&gt;....................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 7232/16512 [============&gt;.................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 8480/16512 [==============&gt;...............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 9664/16512 [================&gt;.............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n10880/16512 [==================&gt;...........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n12096/16512 [====================&gt;.........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n13312/16512 [=======================&gt;......] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n14560/16512 [=========================&gt;....] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n15744/16512 [===========================&gt;..] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n16512/16512 [==============================] - 1s 49us/step - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\nEpoch 2/10\n\n   32/16512 [..............................] - ETA: 1s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 1216/16512 [=&gt;............................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 2432/16512 [===&gt;..........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 3680/16512 [=====&gt;........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 4896/16512 [=======&gt;......................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 6144/16512 [==========&gt;...................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 7360/16512 [============&gt;.................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 8608/16512 [==============&gt;...............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 9824/16512 [================&gt;.............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n11072/16512 [===================&gt;..........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n12288/16512 [=====================&gt;........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n13344/16512 [=======================&gt;......] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n14464/16512 [=========================&gt;....] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n15648/16512 [===========================&gt;..] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n16512/16512 [==============================] - 1s 42us/step - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\nEpoch 3/10\n\n   32/16512 [..............................] - ETA: 1s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 1216/16512 [=&gt;............................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 2432/16512 [===&gt;..........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 3648/16512 [=====&gt;........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 4864/16512 [=======&gt;......................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 6112/16512 [==========&gt;...................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 7328/16512 [============&gt;.................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 8512/16512 [==============&gt;...............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 9728/16512 [================&gt;.............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n10912/16512 [==================&gt;...........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n12192/16512 [=====================&gt;........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n13408/16512 [=======================&gt;......] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n14624/16512 [=========================&gt;....] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n15680/16512 [===========================&gt;..] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n16512/16512 [==============================] - 1s 42us/step - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\nEpoch 4/10\n\n   32/16512 [..............................] - ETA: 1s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 1280/16512 [=&gt;............................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 2496/16512 [===&gt;..........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 3648/16512 [=====&gt;........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 4864/16512 [=======&gt;......................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 5952/16512 [=========&gt;....................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 7168/16512 [============&gt;.................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 8384/16512 [==============&gt;...............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 9568/16512 [================&gt;.............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n10720/16512 [==================&gt;...........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n11872/16512 [====================&gt;.........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n12864/16512 [======================&gt;.......] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n14048/16512 [========================&gt;.....] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n15072/16512 [==========================&gt;...] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n16256/16512 [============================&gt;.] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n16512/16512 [==============================] - 1s 44us/step - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\nEpoch 5/10\n\n   32/16512 [..............................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 1216/16512 [=&gt;............................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 2464/16512 [===&gt;..........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 3680/16512 [=====&gt;........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 4896/16512 [=======&gt;......................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 6080/16512 [==========&gt;...................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 7104/16512 [===========&gt;..................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 8320/16512 [==============&gt;...............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 9536/16512 [================&gt;.............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n10784/16512 [==================&gt;...........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n12000/16512 [====================&gt;.........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n13152/16512 [======================&gt;.......] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n14336/16512 [=========================&gt;....] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n15488/16512 [===========================&gt;..] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n16512/16512 [==============================] - 1s 43us/step - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\nEpoch 6/10\n\n   32/16512 [..............................] - ETA: 1s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 1248/16512 [=&gt;............................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 2464/16512 [===&gt;..........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 3712/16512 [=====&gt;........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 4832/16512 [=======&gt;......................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 5984/16512 [=========&gt;....................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 7136/16512 [===========&gt;..................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 8352/16512 [==============&gt;...............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 9568/16512 [================&gt;.............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n10720/16512 [==================&gt;...........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n11904/16512 [====================&gt;.........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n13088/16512 [======================&gt;.......] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n14272/16512 [========================&gt;.....] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n15488/16512 [===========================&gt;..] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n16512/16512 [==============================] - 1s 43us/step - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\nEpoch 7/10\n\n   32/16512 [..............................] - ETA: 1s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 1216/16512 [=&gt;............................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 2368/16512 [===&gt;..........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 3584/16512 [=====&gt;........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 4800/16512 [=======&gt;......................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 6048/16512 [=========&gt;....................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 7264/16512 [============&gt;.................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 8480/16512 [==============&gt;...............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 9504/16512 [================&gt;.............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n10720/16512 [==================&gt;...........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n11936/16512 [====================&gt;.........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n13088/16512 [======================&gt;.......] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n14080/16512 [========================&gt;.....] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n15200/16512 [==========================&gt;...] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n16256/16512 [============================&gt;.] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n16512/16512 [==============================] - 1s 44us/step - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\nEpoch 8/10\n\n   32/16512 [..............................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 1216/16512 [=&gt;............................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 2368/16512 [===&gt;..........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 3456/16512 [=====&gt;........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 4672/16512 [=======&gt;......................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 5856/16512 [=========&gt;....................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 7040/16512 [===========&gt;..................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 8256/16512 [==============&gt;...............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 9504/16512 [================&gt;.............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n10688/16512 [==================&gt;...........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n11872/16512 [====================&gt;.........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n13088/16512 [======================&gt;.......] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n14304/16512 [========================&gt;.....] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n15456/16512 [===========================&gt;..] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n16512/16512 [==============================] - 1s 43us/step - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\nEpoch 9/10\n\n   32/16512 [..............................] - ETA: 1s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 1216/16512 [=&gt;............................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 2368/16512 [===&gt;..........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 3584/16512 [=====&gt;........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 4864/16512 [=======&gt;......................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 6080/16512 [==========&gt;...................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 7328/16512 [============&gt;.................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 8576/16512 [==============&gt;...............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 9568/16512 [================&gt;.............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n10688/16512 [==================&gt;...........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n11872/16512 [====================&gt;.........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n12960/16512 [======================&gt;.......] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n14112/16512 [========================&gt;.....] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n15328/16512 [==========================&gt;...] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n16512/16512 [==============================] - 1s 43us/step - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\nEpoch 10/10\n\n   32/16512 [..............................] - ETA: 1s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 1248/16512 [=&gt;............................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 2496/16512 [===&gt;..........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 3776/16512 [=====&gt;........................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 4992/16512 [========&gt;.....................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 6176/16512 [==========&gt;...................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 7392/16512 [============&gt;.................] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 8576/16512 [==============&gt;...............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n 9440/16512 [================&gt;.............] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n10656/16512 [==================&gt;...........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n11840/16512 [====================&gt;.........] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n12992/16512 [======================&gt;.......] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n14144/16512 [========================&gt;.....] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n15360/16512 [==========================&gt;...] - ETA: 0s - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n16512/16512 [==============================] - 1s 43us/step - loss: nan - mean_absolute_error: nan - mean_squared_error: nan\n<span class=\"ansired\">Out[</span><span class=\"ansired\">5</span><span class=\"ansired\">]: </span>&lt;keras.callbacks.History at 0x7f0151845160&gt;\n</div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["## 3. Optimizer\n\nWOW! We got a lot of NANs! Let's try this again, but using the Adam optimizer. There are a lot of optimizers out there, and here is a [great blog post](http://ruder.io/optimizing-gradient-descent/) illustrating the various optimizers.\n\nWhen in doubt, the Adam optimizer does a very good job. If you want to adjust any of the hyperparameters, you will need to import the optimizer from `optimizers` instead of passing in the name as a string."],"metadata":{}},{"cell_type":"code","source":["# Configure custom optimizer: \nfrom keras import optimizers\n\nmodel = build_model()\noptimizer=optimizers.Adam(lr=0.001)\n\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\nhistory = model.fit(X_train, y_train, epochs=20)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Epoch 1/20\n\n   32/16512 [..............................] - ETA: 1:36 - loss: 38083.0234 - mean_absolute_error: 178.5176 - mean_squared_error: 38083.0234\n 1088/16512 [&gt;.............................] - ETA: 3s - loss: 5244.2663 - mean_absolute_error: 45.5507 - mean_squared_error: 5244.2663     \n 2144/16512 [==&gt;...........................] - ETA: 1s - loss: 2729.8583 - mean_absolute_error: 27.3206 - mean_squared_error: 2729.8583\n 3200/16512 [====&gt;.........................] - ETA: 1s - loss: 1830.6984 - mean_absolute_error: 18.8846 - mean_squared_error: 1830.6984\n 4256/16512 [======&gt;.......................] - ETA: 1s - loss: 1377.2240 - mean_absolute_error: 14.5346 - mean_squared_error: 1377.2240\n 5344/16512 [========&gt;.....................] - ETA: 0s - loss: 1097.3955 - mean_absolute_error: 11.8370 - mean_squared_error: 1097.3955\n 6432/16512 [==========&gt;...................] - ETA: 0s - loss: 912.3616 - mean_absolute_error: 10.0728 - mean_squared_error: 912.3616  \n 7520/16512 [============&gt;.................] - ETA: 0s - loss: 780.8229 - mean_absolute_error: 8.8205 - mean_squared_error: 780.8229 \n 8640/16512 [==============&gt;...............] - ETA: 0s - loss: 679.9438 - mean_absolute_error: 7.8453 - mean_squared_error: 679.9438\n 9696/16512 [================&gt;.............] - ETA: 0s - loss: 606.1340 - mean_absolute_error: 7.1200 - mean_squared_error: 606.1340\n10688/16512 [==================&gt;...........] - ETA: 0s - loss: 550.0844 - mean_absolute_error: 6.5701 - mean_squared_error: 550.0844\n11712/16512 [====================&gt;.........] - ETA: 0s - loss: 502.1828 - mean_absolute_error: 6.0988 - mean_squared_error: 502.1828\n12736/16512 [======================&gt;.......] - ETA: 0s - loss: 462.0218 - mean_absolute_error: 5.7109 - mean_squared_error: 462.0218\n13760/16512 [========================&gt;.....] - ETA: 0s - loss: 427.8001 - mean_absolute_error: 5.3729 - mean_squared_error: 427.8001\n14848/16512 [=========================&gt;....] - ETA: 0s - loss: 396.6452 - mean_absolute_error: 5.0668 - mean_squared_error: 396.6452\n15936/16512 [===========================&gt;..] - ETA: 0s - loss: 369.7115 - mean_absolute_error: 4.7985 - mean_squared_error: 369.7115\n16512/16512 [==============================] - 1s 59us/step - loss: 356.8892 - mean_absolute_error: 4.6713 - mean_squared_error: 356.8892\nEpoch 2/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 2.4028 - mean_absolute_error: 1.3496 - mean_squared_error: 2.4028\n 1120/16512 [=&gt;............................] - ETA: 0s - loss: 2.2347 - mean_absolute_error: 1.1885 - mean_squared_error: 2.2347\n 2176/16512 [==&gt;...........................] - ETA: 0s - loss: 2.3029 - mean_absolute_error: 1.1907 - mean_squared_error: 2.3029\n 3232/16512 [====&gt;.........................] - ETA: 0s - loss: 2.3221 - mean_absolute_error: 1.1862 - mean_squared_error: 2.3221\n 4288/16512 [======&gt;.......................] - ETA: 0s - loss: 2.2728 - mean_absolute_error: 1.1781 - mean_squared_error: 2.2728\n 5344/16512 [========&gt;.....................] - ETA: 0s - loss: 2.2546 - mean_absolute_error: 1.1719 - mean_squared_error: 2.2546\n 6432/16512 [==========&gt;...................] - ETA: 0s - loss: 2.2046 - mean_absolute_error: 1.1578 - mean_squared_error: 2.2046\n 7456/16512 [============&gt;.................] - ETA: 0s - loss: 2.1569 - mean_absolute_error: 1.1470 - mean_squared_error: 2.1569\n 8512/16512 [==============&gt;...............] - ETA: 0s - loss: 2.1434 - mean_absolute_error: 1.1468 - mean_squared_error: 2.1434\n 9568/16512 [================&gt;.............] - ETA: 0s - loss: 2.1203 - mean_absolute_error: 1.1401 - mean_squared_error: 2.1203\n10656/16512 [==================&gt;...........] - ETA: 0s - loss: 2.0870 - mean_absolute_error: 1.1316 - mean_squared_error: 2.0870\n11776/16512 [====================&gt;.........] - ETA: 0s - loss: 2.1416 - mean_absolute_error: 1.1326 - mean_squared_error: 2.1416\n12864/16512 [======================&gt;.......] - ETA: 0s - loss: 2.1106 - mean_absolute_error: 1.1263 - mean_squared_error: 2.1106\n13920/16512 [========================&gt;.....] - ETA: 0s - loss: 2.1166 - mean_absolute_error: 1.1265 - mean_squared_error: 2.1166\n15008/16512 [==========================&gt;...] - ETA: 0s - loss: 2.1009 - mean_absolute_error: 1.1224 - mean_squared_error: 2.1009\n16064/16512 [============================&gt;.] - ETA: 0s - loss: 2.0763 - mean_absolute_error: 1.1167 - mean_squared_error: 2.0763\n16512/16512 [==============================] - 1s 48us/step - loss: 2.0545 - mean_absolute_error: 1.1104 - mean_squared_error: 2.0545\nEpoch 3/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 4.5388 - mean_absolute_error: 1.2363 - mean_squared_error: 4.5388\n 1120/16512 [=&gt;............................] - ETA: 0s - loss: 1.9890 - mean_absolute_error: 1.0887 - mean_squared_error: 1.9890\n 2208/16512 [===&gt;..........................] - ETA: 0s - loss: 1.9179 - mean_absolute_error: 1.0841 - mean_squared_error: 1.9179\n 3232/16512 [====&gt;.........................] - ETA: 0s - loss: 1.8384 - mean_absolute_error: 1.0567 - mean_squared_error: 1.8384\n 4320/16512 [======&gt;.......................] - ETA: 0s - loss: 1.7763 - mean_absolute_error: 1.0435 - mean_squared_error: 1.7763\n 5440/16512 [========&gt;.....................] - ETA: 0s - loss: 1.7007 - mean_absolute_error: 1.0210 - mean_squared_error: 1.7007\n 6528/16512 [==========&gt;...................] - ETA: 0s - loss: 1.6675 - mean_absolute_error: 1.0131 - mean_squared_error: 1.6675\n 7616/16512 [============&gt;.................] - ETA: 0s - loss: 1.6284 - mean_absolute_error: 0.9986 - mean_squared_error: 1.6284\n 8640/16512 [==============&gt;...............] - ETA: 0s - loss: 1.6070 - mean_absolute_error: 0.9925 - mean_squared_error: 1.6070\n 9728/16512 [================&gt;.............] - ETA: 0s - loss: 1.5855 - mean_absolute_error: 0.9877 - mean_squared_error: 1.5855\n10816/16512 [==================&gt;...........] - ETA: 0s - loss: 1.5845 - mean_absolute_error: 0.9844 - mean_squared_error: 1.5845\n11936/16512 [====================&gt;.........] - ETA: 0s - loss: 1.6866 - mean_absolute_error: 1.0091 - mean_squared_error: 1.6866\n12992/16512 [======================&gt;.......] - ETA: 0s - loss: 1.6630 - mean_absolute_error: 1.0018 - mean_squared_error: 1.6630\n14080/16512 [========================&gt;.....] - ETA: 0s - loss: 1.6310 - mean_absolute_error: 0.9929 - mean_squared_error: 1.6310\n15200/16512 [==========================&gt;...] - ETA: 0s - loss: 1.5990 - mean_absolute_error: 0.9835 - mean_squared_error: 1.5990\n16320/16512 [============================&gt;.] - ETA: 0s - loss: 1.5721 - mean_absolute_error: 0.9753 - mean_squared_error: 1.5721\n16512/16512 [==============================] - 1s 47us/step - loss: 1.5679 - mean_absolute_error: 0.9744 - mean_squared_error: 1.5679\nEpoch 4/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 1.3491 - mean_absolute_error: 0.9652 - mean_squared_error: 1.3491\n 1120/16512 [=&gt;............................] - ETA: 0s - loss: 1.2667 - mean_absolute_error: 0.8900 - mean_squared_error: 1.2667\n 2112/16512 [==&gt;...........................] - ETA: 0s - loss: 1.3316 - mean_absolute_error: 0.9178 - mean_squared_error: 1.3316\n 3200/16512 [====&gt;.........................] - ETA: 0s - loss: 1.2983 - mean_absolute_error: 0.8947 - mean_squared_error: 1.2983\n 4288/16512 [======&gt;.......................] - ETA: 0s - loss: 1.3791 - mean_absolute_error: 0.9263 - mean_squared_error: 1.3791\n 5312/16512 [========&gt;.....................] - ETA: 0s - loss: 1.4170 - mean_absolute_error: 0.9351 - mean_squared_error: 1.4170\n 6400/16512 [==========&gt;...................] - ETA: 0s - loss: 1.3964 - mean_absolute_error: 0.9278 - mean_squared_error: 1.3964\n 7392/16512 [============&gt;.................] - ETA: 0s - loss: 1.3581 - mean_absolute_error: 0.9149 - mean_squared_error: 1.3581\n 8480/16512 [==============&gt;...............] - ETA: 0s - loss: 1.3268 - mean_absolute_error: 0.9047 - mean_squared_error: 1.3268\n 9536/16512 [================&gt;.............] - ETA: 0s - loss: 1.3028 - mean_absolute_error: 0.8948 - mean_squared_error: 1.3028\n10592/16512 [==================&gt;...........] - ETA: 0s - loss: 1.2737 - mean_absolute_error: 0.8855 - mean_squared_error: 1.2737\n11680/16512 [====================&gt;.........] - ETA: 0s - loss: 1.2584 - mean_absolute_error: 0.8800 - mean_squared_error: 1.2584\n12768/16512 [======================&gt;.......] - ETA: 0s - loss: 1.2429 - mean_absolute_error: 0.8746 - mean_squared_error: 1.2429\n13824/16512 [========================&gt;.....] - ETA: 0s - loss: 1.2814 - mean_absolute_error: 0.8814 - mean_squared_error: 1.2814\n14912/16512 [==========================&gt;...] - ETA: 0s - loss: 1.2826 - mean_absolute_error: 0.8816 - mean_squared_error: 1.2826\n16000/16512 [============================&gt;.] - ETA: 0s - loss: 1.2628 - mean_absolute_error: 0.8753 - mean_squared_error: 1.2628\n16512/16512 [==============================] - 1s 48us/step - loss: 1.2515 - mean_absolute_error: 0.8708 - mean_squared_error: 1.2515\nEpoch 5/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 1.1006 - mean_absolute_error: 0.7592 - mean_squared_error: 1.1006\n 1056/16512 [&gt;.............................] - ETA: 0s - loss: 0.9200 - mean_absolute_error: 0.7510 - mean_squared_error: 0.9200\n 2144/16512 [==&gt;...........................] - ETA: 0s - loss: 0.9609 - mean_absolute_error: 0.7679 - mean_squared_error: 0.9609\n 3200/16512 [====&gt;.........................] - ETA: 0s - loss: 0.9450 - mean_absolute_error: 0.7608 - mean_squared_error: 0.9450\n 4288/16512 [======&gt;.......................] - ETA: 0s - loss: 1.3909 - mean_absolute_error: 0.8481 - mean_squared_error: 1.3909\n 5376/16512 [========&gt;.....................] - ETA: 0s - loss: 1.4445 - mean_absolute_error: 0.8762 - mean_squared_error: 1.4445\n 6432/16512 [==========&gt;...................] - ETA: 0s - loss: 1.3946 - mean_absolute_error: 0.8691 - mean_squared_error: 1.3946\n 7488/16512 [============&gt;.................] - ETA: 0s - loss: 1.3438 - mean_absolute_error: 0.8564 - mean_squared_error: 1.3438\n 8480/16512 [==============&gt;...............] - ETA: 0s - loss: 1.2886 - mean_absolute_error: 0.8360 - mean_squared_error: 1.2886\n 9504/16512 [================&gt;.............] - ETA: 0s - loss: 1.2838 - mean_absolute_error: 0.8374 - mean_squared_error: 1.2838\n10560/16512 [==================&gt;...........] - ETA: 0s - loss: 1.2442 - mean_absolute_error: 0.8265 - mean_squared_error: 1.2442\n11584/16512 [====================&gt;.........] - ETA: 0s - loss: 1.2142 - mean_absolute_error: 0.8186 - mean_squared_error: 1.2142\n12704/16512 [======================&gt;.......] - ETA: 0s - loss: 1.1900 - mean_absolute_error: 0.8114 - mean_squared_error: 1.1900\n13792/16512 [========================&gt;.....] - ETA: 0s - loss: 1.1761 - mean_absolute_error: 0.8086 - mean_squared_error: 1.1761\n14848/16512 [=========================&gt;....] - ETA: 0s - loss: 1.2186 - mean_absolute_error: 0.8189 - mean_squared_error: 1.2186\n15936/16512 [===========================&gt;..] - ETA: 0s - loss: 1.3218 - mean_absolute_error: 0.8484 - mean_squared_error: 1.3218\n16512/16512 [==============================] - 1s 48us/step - loss: 1.4229 - mean_absolute_error: 0.8692 - mean_squared_error: 1.4229\nEpoch 6/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 3.0354 - mean_absolute_error: 1.3893 - mean_squared_error: 3.0354\n 1120/16512 [=&gt;............................] - ETA: 0s - loss: 1.4647 - mean_absolute_error: 0.9030 - mean_squared_error: 1.4647\n 2208/16512 [===&gt;..........................] - ETA: 0s - loss: 1.2264 - mean_absolute_error: 0.8383 - mean_squared_error: 1.2264\n 3232/16512 [====&gt;.........................] - ETA: 0s - loss: 1.1421 - mean_absolute_error: 0.7992 - mean_squared_error: 1.1421\n 4320/16512 [======&gt;.......................] - ETA: 0s - loss: 1.0706 - mean_absolute_error: 0.7780 - mean_squared_error: 1.0706\n 5376/16512 [========&gt;.....................] - ETA: 0s - loss: 1.0190 - mean_absolute_error: 0.7602 - mean_squared_error: 1.0190\n 6432/16512 [==========&gt;...................] - ETA: 0s - loss: 0.9882 - mean_absolute_error: 0.7503 - mean_squared_error: 0.9882\n 7520/16512 [============&gt;.................] - ETA: 0s - loss: 0.9639 - mean_absolute_error: 0.7458 - mean_squared_error: 0.9639\n 8576/16512 [==============&gt;...............] - ETA: 0s - loss: 0.9529 - mean_absolute_error: 0.7425 - mean_squared_error: 0.9529\n 9632/16512 [================&gt;.............] - ETA: 0s - loss: 5.8905 - mean_absolute_error: 1.2018 - mean_squared_error: 5.8905\n10688/16512 [==================&gt;...........] - ETA: 0s - loss: 6.6804 - mean_absolute_error: 1.3404 - mean_squared_error: 6.6804\n11744/16512 [====================&gt;.........] - ETA: 0s - loss: 6.8004 - mean_absolute_error: 1.4001 - mean_squared_error: 6.8004\n12832/16512 [======================&gt;.......] - ETA: 0s - loss: 6.4114 - mean_absolute_error: 1.3790 - mean_squared_error: 6.4114\n13920/16512 [========================&gt;.....] - ETA: 0s - loss: 6.0032 - mean_absolute_error: 1.3363 - mean_squared_error: 6.0032\n15008/16512 [==========================&gt;...] - ETA: 0s - loss: 5.6513 - mean_absolute_error: 1.2991 - mean_squared_error: 5.6513\n16096/16512 [============================&gt;.] - ETA: 0s - loss: 5.3745 - mean_absolute_error: 1.2680 - mean_squared_error: 5.3745\n16512/16512 [==============================] - 1s 47us/step - loss: 5.3506 - mean_absolute_error: 1.2778 - mean_squared_error: 5.3506\nEpoch 7/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 2.1616 - mean_absolute_error: 1.0875 - mean_squared_error: 2.1616\n 1120/16512 [=&gt;............................] - ETA: 0s - loss: 2.6831 - mean_absolute_error: 1.1266 - mean_squared_error: 2.6831\n 2176/16512 [==&gt;...........................] - ETA: 0s - loss: 1.7505 - mean_absolute_error: 0.8985 - mean_squared_error: 1.7505\n 3264/16512 [====&gt;.........................] - ETA: 0s - loss: 1.6299 - mean_absolute_error: 0.8893 - mean_squared_error: 1.6299\n 4288/16512 [======&gt;.......................] - ETA: 0s - loss: 1.6118 - mean_absolute_error: 0.9012 - mean_squared_error: 1.6118\n 5312/16512 [========&gt;.....................] - ETA: 0s - loss: 4.8919 - mean_absolute_error: 1.2544 - mean_squared_error: 4.8919\n 6400/16512 [==========&gt;...................] - ETA: 0s - loss: 4.7147 - mean_absolute_error: 1.2830 - mean_squared_error: 4.7147\n 7424/16512 [============&gt;.................] - ETA: 0s - loss: 4.1818 - mean_absolute_error: 1.2038 - mean_squared_error: 4.1818\n 8448/16512 [==============&gt;...............] - ETA: 0s - loss: 3.7814 - mean_absolute_error: 1.1446 - mean_squared_error: 3.7814\n 9504/16512 [================&gt;.............] - ETA: 0s - loss: 3.4444 - mean_absolute_error: 1.0918 - mean_squared_error: 3.4444\n10560/16512 [==================&gt;...........] - ETA: 0s - loss: 3.1746 - mean_absolute_error: 1.0483 - mean_squared_error: 3.1746\n11584/16512 [====================&gt;.........] - ETA: 0s - loss: 2.9697 - mean_absolute_error: 1.0181 - mean_squared_error: 2.9697\n12672/16512 [======================&gt;.......] - ETA: 0s - loss: 2.7942 - mean_absolute_error: 0.9950 - mean_squared_error: 2.7942\n13728/16512 [=======================&gt;......] - ETA: 0s - loss: 2.6511 - mean_absolute_error: 0.9751 - mean_squared_error: 2.6511\n14656/16512 [=========================&gt;....] - ETA: 0s - loss: 2.5467 - mean_absolute_error: 0.9631 - mean_squared_error: 2.5467\n15712/16512 [===========================&gt;..] - ETA: 0s - loss: 2.4464 - mean_absolute_error: 0.9516 - mean_squared_error: 2.4464\n16512/16512 [==============================] - 1s 48us/step - loss: 2.3684 - mean_absolute_error: 0.9397 - mean_squared_error: 2.3684\nEpoch 8/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 2.3183 - mean_absolute_error: 0.9423 - mean_squared_error: 2.3183\n 1088/16512 [&gt;.............................] - ETA: 0s - loss: 0.7622 - mean_absolute_error: 0.6574 - mean_squared_error: 0.7622\n 2144/16512 [==&gt;...........................] - ETA: 0s - loss: 0.9057 - mean_absolute_error: 0.7153 - mean_squared_error: 0.9057\n 3232/16512 [====&gt;.........................] - ETA: 0s - loss: 0.8994 - mean_absolute_error: 0.7186 - mean_squared_error: 0.8994\n 4320/16512 [======&gt;.......................] - ETA: 0s - loss: 0.8803 - mean_absolute_error: 0.7138 - mean_squared_error: 0.8803\n 5440/16512 [========&gt;.....................] - ETA: 0s - loss: 0.8960 - mean_absolute_error: 0.7219 - mean_squared_error: 0.8960\n 6496/16512 [==========&gt;...................] - ETA: 0s - loss: 0.9190 - mean_absolute_error: 0.7241 - mean_squared_error: 0.9190\n 7552/16512 [============&gt;.................] - ETA: 0s - loss: 0.9990 - mean_absolute_error: 0.7551 - mean_squared_error: 0.9990\n 8640/16512 [==============&gt;...............] - ETA: 0s - loss: 1.1547 - mean_absolute_error: 0.8036 - mean_squared_error: 1.1547\n 9696/16512 [================&gt;.............] - ETA: 0s - loss: 1.1252 - mean_absolute_error: 0.7939 - mean_squared_error: 1.1252\n10752/16512 [==================&gt;...........] - ETA: 0s - loss: 1.1035 - mean_absolute_error: 0.7870 - mean_squared_error: 1.1035\n11744/16512 [====================&gt;.........] - ETA: 0s - loss: 1.0802 - mean_absolute_error: 0.7793 - mean_squared_error: 1.0802\n12800/16512 [======================&gt;.......] - ETA: 0s - loss: 1.0611 - mean_absolute_error: 0.7724 - mean_squared_error: 1.0611\n13856/16512 [========================&gt;.....] - ETA: 0s - loss: 1.0437 - mean_absolute_error: 0.7673 - mean_squared_error: 1.0437\n14944/16512 [==========================&gt;...] - ETA: 0s - loss: 1.0247 - mean_absolute_error: 0.7610 - mean_squared_error: 1.0247\n15968/16512 [============================&gt;.] - ETA: 0s - loss: 1.1355 - mean_absolute_error: 0.7894 - mean_squared_error: 1.1355\n16512/16512 [==============================] - 1s 48us/step - loss: 1.1745 - mean_absolute_error: 0.8016 - mean_squared_error: 1.1745\nEpoch 9/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 1.4865 - mean_absolute_error: 1.0354 - mean_squared_error: 1.4865\n 1120/16512 [=&gt;............................] - ETA: 0s - loss: 2.5041 - mean_absolute_error: 1.1574 - mean_squared_error: 2.5041\n 2176/16512 [==&gt;...........................] - ETA: 0s - loss: 1.6729 - mean_absolute_error: 0.9262 - mean_squared_error: 1.6729\n 3232/16512 [====&gt;.........................] - ETA: 0s - loss: 1.4304 - mean_absolute_error: 0.8635 - mean_squared_error: 1.4304\n 4288/16512 [======&gt;.......................] - ETA: 0s - loss: 1.4818 - mean_absolute_error: 0.8875 - mean_squared_error: 1.4818\n 5344/16512 [========&gt;.....................] - ETA: 0s - loss: 1.7459 - mean_absolute_error: 0.9693 - mean_squared_error: 1.7459\n 6400/16512 [==========&gt;...................] - ETA: 0s - loss: 1.7928 - mean_absolute_error: 0.9893 - mean_squared_error: 1.7928\n 7488/16512 [============&gt;.................] - ETA: 0s - loss: 3.2570 - mean_absolute_error: 1.2120 - mean_squared_error: 3.2570\n 8544/16512 [==============&gt;...............] - ETA: 0s - loss: 6.1090 - mean_absolute_error: 1.4948 - mean_squared_error: 6.1090\n 9600/16512 [================&gt;.............] - ETA: 0s - loss: 6.4331 - mean_absolute_error: 1.5605 - mean_squared_error: 6.4331\n10368/16512 [=================&gt;............] - ETA: 0s - loss: 6.0692 - mean_absolute_error: 1.5118 - mean_squared_error: 6.0692\n11456/16512 [===================&gt;..........] - ETA: 0s - loss: 6.5365 - mean_absolute_error: 1.5813 - mean_squared_error: 6.5365\n12544/16512 [=====================&gt;........] - ETA: 0s - loss: 6.2434 - mean_absolute_error: 1.5582 - mean_squared_error: 6.2434\n13536/16512 [=======================&gt;......] - ETA: 0s - loss: 6.0700 - mean_absolute_error: 1.5465 - mean_squared_error: 6.0700\n14624/16512 [=========================&gt;....] - ETA: 0s - loss: 5.9220 - mean_absolute_error: 1.5359 - mean_squared_error: 5.9220\n15680/16512 [===========================&gt;..] - ETA: 0s - loss: 5.6060 - mean_absolute_error: 1.4899 - mean_squared_error: 5.6060\n16512/16512 [==============================] - 1s 49us/step - loss: 5.4165 - mean_absolute_error: 1.4669 - mean_squared_error: 5.4165\nEpoch 10/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 2.4929 - mean_absolute_error: 1.3806 - mean_squared_error: 2.4929\n 1120/16512 [=&gt;............................] - ETA: 0s - loss: 1.1314 - mean_absolute_error: 0.7966 - mean_squared_error: 1.1314\n 2176/16512 [==&gt;...........................] - ETA: 0s - loss: 0.9541 - mean_absolute_error: 0.7371 - mean_squared_error: 0.9541\n 3232/16512 [====&gt;.........................] - ETA: 0s - loss: 32.3333 - mean_absolute_error: 2.3834 - mean_squared_error: 32.3333\n 4288/16512 [======&gt;.......................] - ETA: 0s - loss: 27.5738 - mean_absolute_error: 2.3873 - mean_squared_error: 27.5738\n 5312/16512 [========&gt;.....................] - ETA: 0s - loss: 22.5540 - mean_absolute_error: 2.1173 - mean_squared_error: 22.5540\n 6368/16512 [==========&gt;...................] - ETA: 0s - loss: 19.1038 - mean_absolute_error: 1.9313 - mean_squared_error: 19.1038\n 7360/16512 [============&gt;.................] - ETA: 0s - loss: 16.6635 - mean_absolute_error: 1.7769 - mean_squared_error: 16.6635\n 8448/16512 [==============&gt;...............] - ETA: 0s - loss: 14.6502 - mean_absolute_error: 1.6489 - mean_squared_error: 14.6502\n 9504/16512 [================&gt;.............] - ETA: 0s - loss: 13.1411 - mean_absolute_error: 1.5527 - mean_squared_error: 13.1411\n10592/16512 [==================&gt;...........] - ETA: 0s - loss: 11.8671 - mean_absolute_error: 1.4607 - mean_squared_error: 11.8671\n11648/16512 [====================&gt;.........] - ETA: 0s - loss: 10.8626 - mean_absolute_error: 1.3908 - mean_squared_error: 10.8626\n12704/16512 [======================&gt;.......] - ETA: 0s - loss: 10.0272 - mean_absolute_error: 1.3327 - mean_squared_error: 10.0272\n13792/16512 [========================&gt;.....] - ETA: 0s - loss: 9.3150 - mean_absolute_error: 1.2884 - mean_squared_error: 9.3150  \n14752/16512 [=========================&gt;....] - ETA: 0s - loss: 8.8025 - mean_absolute_error: 1.2620 - mean_squared_error: 8.8025\n15712/16512 [===========================&gt;..] - ETA: 0s - loss: 8.3483 - mean_absolute_error: 1.2382 - mean_squared_error: 8.3483\n16512/16512 [==============================] - 1s 49us/step - loss: 8.0195 - mean_absolute_error: 1.2223 - mean_squared_error: 8.0195\nEpoch 11/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 0.8817 - mean_absolute_error: 0.7319 - mean_squared_error: 0.8817\n 1024/16512 [&gt;.............................] - ETA: 0s - loss: 1.2045 - mean_absolute_error: 0.8291 - mean_squared_error: 1.2045\n 2080/16512 [==&gt;...........................] - ETA: 0s - loss: 1.1631 - mean_absolute_error: 0.8208 - mean_squared_error: 1.1631\n 3008/16512 [====&gt;.........................] - ETA: 0s - loss: 1.0191 - mean_absolute_error: 0.7641 - mean_squared_error: 1.0191\n 4096/16512 [======&gt;.......................] - ETA: 0s - loss: 1.0089 - mean_absolute_error: 0.7582 - mean_squared_error: 1.0089\n 5152/16512 [========&gt;.....................] - ETA: 0s - loss: 1.0310 - mean_absolute_error: 0.7671 - mean_squared_error: 1.0310\n 6144/16512 [==========&gt;...................] - ETA: 0s - loss: 0.9759 - mean_absolute_error: 0.7447 - mean_squared_error: 0.9759\n 7168/16512 [============&gt;.................] - ETA: 0s - loss: 0.9501 - mean_absolute_error: 0.7357 - mean_squared_error: 0.9501\n 8224/16512 [=============&gt;................] - ETA: 0s - loss: 0.9467 - mean_absolute_error: 0.7361 - mean_squared_error: 0.9467\n 9280/16512 [===============&gt;..............] - ETA: 0s - loss: 0.9643 - mean_absolute_error: 0.7433 - mean_squared_error: 0.9643\n10368/16512 [=================&gt;............] - ETA: 0s - loss: 0.9745 - mean_absolute_error: 0.7455 - mean_squared_error: 0.9745\n11392/16512 [===================&gt;..........] - ETA: 0s - loss: 1.0602 - mean_absolute_error: 0.7708 - mean_squared_error: 1.0602\n12416/16512 [=====================&gt;........] - ETA: 0s - loss: 1.1048 - mean_absolute_error: 0.7867 - mean_squared_error: 1.1048\n13440/16512 [=======================&gt;......] - ETA: 0s - loss: 1.4604 - mean_absolute_error: 0.8610 - mean_squared_error: 1.4604\n14528/16512 [=========================&gt;....] - ETA: 0s - loss: 1.4291 - mean_absolute_error: 0.8536 - mean_squared_error: 1.4291\n15616/16512 [===========================&gt;..] - ETA: 0s - loss: 1.8222 - mean_absolute_error: 0.8873 - mean_squared_error: 1.8222\n16512/16512 [==============================] - 1s 49us/step - loss: 4.7099 - mean_absolute_error: 1.1189 - mean_squared_error: 4.7099\nEpoch 12/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 75.4262 - mean_absolute_error: 7.6448 - mean_squared_error: 75.4262\n 1088/16512 [&gt;.............................] - ETA: 0s - loss: 21.1186 - mean_absolute_error: 3.2737 - mean_squared_error: 21.1186\n 2080/16512 [==&gt;...........................] - ETA: 0s - loss: 21.9140 - mean_absolute_error: 3.3993 - mean_squared_error: 21.9140\n 3072/16512 [====&gt;.........................] - ETA: 0s - loss: 21.0281 - mean_absolute_error: 3.2959 - mean_squared_error: 21.0281\n 4128/16512 [======&gt;.......................] - ETA: 0s - loss: 16.3312 - mean_absolute_error: 2.7536 - mean_squared_error: 16.3312\n 5120/16512 [========&gt;.....................] - ETA: 0s - loss: 14.5504 - mean_absolute_error: 2.6000 - mean_squared_error: 14.5504\n 6208/16512 [==========&gt;...................] - ETA: 0s - loss: 12.1850 - mean_absolute_error: 2.2736 - mean_squared_error: 12.1850\n 7232/16512 [============&gt;.................] - ETA: 0s - loss: 10.5856 - mean_absolute_error: 2.0537 - mean_squared_error: 10.5856\n 8256/16512 [==============&gt;...............] - ETA: 0s - loss: 9.3806 - mean_absolute_error: 1.8861 - mean_squared_error: 9.3806  \n 9248/16512 [===============&gt;..............] - ETA: 0s - loss: 8.5029 - mean_absolute_error: 1.7693 - mean_squared_error: 8.5029\n10304/16512 [=================&gt;............] - ETA: 0s - loss: 7.7560 - mean_absolute_error: 1.6702 - mean_squared_error: 7.7560\n11392/16512 [===================&gt;..........] - ETA: 0s - loss: 7.0844 - mean_absolute_error: 1.5711 - mean_squared_error: 7.0844\n12448/16512 [=====================&gt;........] - ETA: 0s - loss: 6.5403 - mean_absolute_error: 1.4911 - mean_squared_error: 6.5403\n13536/16512 [=======================&gt;......] - ETA: 0s - loss: 6.0822 - mean_absolute_error: 1.4264 - mean_squared_error: 6.0822\n14560/16512 [=========================&gt;....] - ETA: 0s - loss: 5.6980 - mean_absolute_error: 1.3686 - mean_squared_error: 5.6980\n15520/16512 [===========================&gt;..] - ETA: 0s - loss: 5.3950 - mean_absolute_error: 1.3254 - mean_squared_error: 5.3950\n16512/16512 [==============================] - 1s 49us/step - loss: 5.1176 - mean_absolute_error: 1.2860 - mean_squared_error: 5.1176\nEpoch 13/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 0.5866 - mean_absolute_error: 0.5550 - mean_squared_error: 0.5866\n  928/16512 [&gt;.............................] - ETA: 0s - loss: 0.8974 - mean_absolute_error: 0.7324 - mean_squared_error: 0.8974\n 1984/16512 [==&gt;...........................] - ETA: 0s - loss: 0.8025 - mean_absolute_error: 0.6940 - mean_squared_error: 0.8025\n 2976/16512 [====&gt;.........................] - ETA: 0s - loss: 1.3105 - mean_absolute_error: 0.8101 - mean_squared_error: 1.3105\n 3968/16512 [======&gt;.......................] - ETA: 0s - loss: 1.3030 - mean_absolute_error: 0.8212 - mean_squared_error: 1.3030\n 5024/16512 [========&gt;.....................] - ETA: 0s - loss: 1.3887 - mean_absolute_error: 0.8467 - mean_squared_error: 1.3887\n 6112/16512 [==========&gt;...................] - ETA: 0s - loss: 1.4436 - mean_absolute_error: 0.8631 - mean_squared_error: 1.4436\n 7168/16512 [============&gt;.................] - ETA: 0s - loss: 1.3610 - mean_absolute_error: 0.8429 - mean_squared_error: 1.3610\n 8192/16512 [=============&gt;................] - ETA: 0s - loss: 1.8414 - mean_absolute_error: 0.9507 - mean_squared_error: 1.8414\n 9280/16512 [===============&gt;..............] - ETA: 0s - loss: 1.9162 - mean_absolute_error: 0.9725 - mean_squared_error: 1.9162\n10336/16512 [=================&gt;............] - ETA: 0s - loss: 1.8978 - mean_absolute_error: 0.9733 - mean_squared_error: 1.8978\n11392/16512 [===================&gt;..........] - ETA: 0s - loss: 1.8249 - mean_absolute_error: 0.9592 - mean_squared_error: 1.8249\n12448/16512 [=====================&gt;........] - ETA: 0s - loss: 1.9902 - mean_absolute_error: 0.9906 - mean_squared_error: 1.9902\n13472/16512 [=======================&gt;......] - ETA: 0s - loss: 14.5598 - mean_absolute_error: 1.5965 - mean_squared_error: 14.5598\n14528/16512 [=========================&gt;....] - ETA: 0s - loss: 18.2443 - mean_absolute_error: 1.9080 - mean_squared_error: 18.2443\n15584/16512 [===========================&gt;..] - ETA: 0s - loss: 19.0446 - mean_absolute_error: 2.0288 - mean_squared_error: 19.0446\n16512/16512 [==============================] - 1s 49us/step - loss: 18.3845 - mean_absolute_error: 2.0243 - mean_squared_error: 18.3845\nEpoch 14/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 0.6684 - mean_absolute_error: 0.7126 - mean_squared_error: 0.6684\n 1120/16512 [=&gt;............................] - ETA: 0s - loss: 1.6884 - mean_absolute_error: 0.9926 - mean_squared_error: 1.6884\n 2176/16512 [==&gt;...........................] - ETA: 0s - loss: 1.6216 - mean_absolute_error: 0.9696 - mean_squared_error: 1.6216\n 3200/16512 [====&gt;.........................] - ETA: 0s - loss: 3.2978 - mean_absolute_error: 1.1893 - mean_squared_error: 3.2978\n 4224/16512 [======&gt;.......................] - ETA: 0s - loss: 2.8245 - mean_absolute_error: 1.1165 - mean_squared_error: 2.8245\n 5280/16512 [========&gt;.....................] - ETA: 0s - loss: 2.4477 - mean_absolute_error: 1.0408 - mean_squared_error: 2.4477\n 6336/16512 [==========&gt;...................] - ETA: 0s - loss: 2.1807 - mean_absolute_error: 0.9865 - mean_squared_error: 2.1807\n 7424/16512 [============&gt;.................] - ETA: 0s - loss: 2.0123 - mean_absolute_error: 0.9539 - mean_squared_error: 2.0123\n 8480/16512 [==============&gt;...............] - ETA: 0s - loss: 1.8699 - mean_absolute_error: 0.9253 - mean_squared_error: 1.8699\n 9504/16512 [================&gt;.............] - ETA: 0s - loss: 1.7724 - mean_absolute_error: 0.9072 - mean_squared_error: 1.7724\n10592/16512 [==================&gt;...........] - ETA: 0s - loss: 1.6975 - mean_absolute_error: 0.8941 - mean_squared_error: 1.6975\n11680/16512 [====================&gt;.........] - ETA: 0s - loss: 1.6143 - mean_absolute_error: 0.8738 - mean_squared_error: 1.6143\n12672/16512 [======================&gt;.......] - ETA: 0s - loss: 1.5479 - mean_absolute_error: 0.8576 - mean_squared_error: 1.5479\n13760/16512 [========================&gt;.....] - ETA: 0s - loss: 1.5052 - mean_absolute_error: 0.8505 - mean_squared_error: 1.5052\n14848/16512 [=========================&gt;....] - ETA: 0s - loss: 1.4603 - mean_absolute_error: 0.8408 - mean_squared_error: 1.4603\n15904/16512 [===========================&gt;..] - ETA: 0s - loss: 1.4158 - mean_absolute_error: 0.8294 - mean_squared_error: 1.4158\n16512/16512 [==============================] - 1s 48us/step - loss: 1.3893 - mean_absolute_error: 0.8227 - mean_squared_error: 1.3893\nEpoch 15/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 0.5582 - mean_absolute_error: 0.5854 - mean_squared_error: 0.5582\n 1024/16512 [&gt;.............................] - ETA: 0s - loss: 0.7707 - mean_absolute_error: 0.6867 - mean_squared_error: 0.7707\n 2112/16512 [==&gt;...........................] - ETA: 0s - loss: 0.9386 - mean_absolute_error: 0.7436 - mean_squared_error: 0.9386\n 3200/16512 [====&gt;.........................] - ETA: 0s - loss: 0.9473 - mean_absolute_error: 0.7373 - mean_squared_error: 0.9473\n 4256/16512 [======&gt;.......................] - ETA: 0s - loss: 0.9175 - mean_absolute_error: 0.7266 - mean_squared_error: 0.9175\n 5376/16512 [========&gt;.....................] - ETA: 0s - loss: 0.9866 - mean_absolute_error: 0.7469 - mean_squared_error: 0.9866\n 6464/16512 [==========&gt;...................] - ETA: 0s - loss: 8.2454 - mean_absolute_error: 1.2786 - mean_squared_error: 8.2454\n 7552/16512 [============&gt;.................] - ETA: 0s - loss: 9.8190 - mean_absolute_error: 1.5485 - mean_squared_error: 9.8190\n 8640/16512 [==============&gt;...............] - ETA: 0s - loss: 8.7499 - mean_absolute_error: 1.4637 - mean_squared_error: 8.7499\n 9664/16512 [================&gt;.............] - ETA: 0s - loss: 7.9020 - mean_absolute_error: 1.3809 - mean_squared_error: 7.9020\n10752/16512 [==================&gt;...........] - ETA: 0s - loss: 7.1998 - mean_absolute_error: 1.3174 - mean_squared_error: 7.1998\n11840/16512 [====================&gt;.........] - ETA: 0s - loss: 6.6295 - mean_absolute_error: 1.2655 - mean_squared_error: 6.6295\n12928/16512 [======================&gt;.......] - ETA: 0s - loss: 6.1438 - mean_absolute_error: 1.2191 - mean_squared_error: 6.1438\n13856/16512 [========================&gt;.....] - ETA: 0s - loss: 5.8225 - mean_absolute_error: 1.1977 - mean_squared_error: 5.8225\n14944/16512 [==========================&gt;...] - ETA: 0s - loss: 5.5164 - mean_absolute_error: 1.1814 - mean_squared_error: 5.5164\n16000/16512 [============================&gt;.] - ETA: 0s - loss: 5.2112 - mean_absolute_error: 1.1506 - mean_squared_error: 5.2112\n16512/16512 [==============================] - 1s 48us/step - loss: 5.0742 - mean_absolute_error: 1.1361 - mean_squared_error: 5.0742\nEpoch 16/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 0.6872 - mean_absolute_error: 0.5953 - mean_squared_error: 0.6872\n 1120/16512 [=&gt;............................] - ETA: 0s - loss: 0.7881 - mean_absolute_error: 0.6723 - mean_squared_error: 0.7881\n 2176/16512 [==&gt;...........................] - ETA: 0s - loss: 0.9190 - mean_absolute_error: 0.7234 - mean_squared_error: 0.9190\n 3232/16512 [====&gt;.........................] - ETA: 0s - loss: 0.8732 - mean_absolute_error: 0.7014 - mean_squared_error: 0.8732\n 4288/16512 [======&gt;.......................] - ETA: 0s - loss: 0.8394 - mean_absolute_error: 0.6915 - mean_squared_error: 0.8394\n 5376/16512 [========&gt;.....................] - ETA: 0s - loss: 0.8165 - mean_absolute_error: 0.6846 - mean_squared_error: 0.8165\n 6368/16512 [==========&gt;...................] - ETA: 0s - loss: 0.8226 - mean_absolute_error: 0.6886 - mean_squared_error: 0.8226\n 7424/16512 [============&gt;.................] - ETA: 0s - loss: 0.8231 - mean_absolute_error: 0.6905 - mean_squared_error: 0.8231\n 8480/16512 [==============&gt;...............] - ETA: 0s - loss: 0.8882 - mean_absolute_error: 0.7113 - mean_squared_error: 0.8882\n 9536/16512 [================&gt;.............] - ETA: 0s - loss: 0.8985 - mean_absolute_error: 0.7161 - mean_squared_error: 0.8985\n10592/16512 [==================&gt;...........] - ETA: 0s - loss: 0.8873 - mean_absolute_error: 0.7125 - mean_squared_error: 0.8873\n11584/16512 [====================&gt;.........] - ETA: 0s - loss: 0.8809 - mean_absolute_error: 0.7087 - mean_squared_error: 0.8809\n12608/16512 [=====================&gt;........] - ETA: 0s - loss: 0.8859 - mean_absolute_error: 0.7099 - mean_squared_error: 0.8859\n13632/16512 [=======================&gt;......] - ETA: 0s - loss: 0.8736 - mean_absolute_error: 0.7052 - mean_squared_error: 0.8736\n14656/16512 [=========================&gt;....] - ETA: 0s - loss: 0.8894 - mean_absolute_error: 0.7113 - mean_squared_error: 0.8894\n15712/16512 [===========================&gt;..] - ETA: 0s - loss: 0.8959 - mean_absolute_error: 0.7140 - mean_squared_error: 0.8959\n16512/16512 [==============================] - 1s 49us/step - loss: 0.8974 - mean_absolute_error: 0.7148 - mean_squared_error: 0.8974\nEpoch 17/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 0.7131 - mean_absolute_error: 0.6614 - mean_squared_error: 0.7131\n 1120/16512 [=&gt;............................] - ETA: 0s - loss: 0.7284 - mean_absolute_error: 0.6579 - mean_squared_error: 0.7284\n 2176/16512 [==&gt;...........................] - ETA: 0s - loss: 0.8332 - mean_absolute_error: 0.6986 - mean_squared_error: 0.8332\n 3264/16512 [====&gt;.........................] - ETA: 0s - loss: 0.8025 - mean_absolute_error: 0.6824 - mean_squared_error: 0.8025\n 4352/16512 [======&gt;.......................] - ETA: 0s - loss: 0.7954 - mean_absolute_error: 0.6784 - mean_squared_error: 0.7954\n 5376/16512 [========&gt;.....................] - ETA: 0s - loss: 0.9050 - mean_absolute_error: 0.6951 - mean_squared_error: 0.9050\n 6464/16512 [==========&gt;...................] - ETA: 0s - loss: 6.3475 - mean_absolute_error: 1.2909 - mean_squared_error: 6.3475\n 7488/16512 [============&gt;.................] - ETA: 0s - loss: 6.2036 - mean_absolute_error: 1.3262 - mean_squared_error: 6.2036\n 8544/16512 [==============&gt;...............] - ETA: 0s - loss: 5.5378 - mean_absolute_error: 1.2476 - mean_squared_error: 5.5378\n 9600/16512 [================&gt;.............] - ETA: 0s - loss: 5.0307 - mean_absolute_error: 1.1921 - mean_squared_error: 5.0307\n10688/16512 [==================&gt;...........] - ETA: 0s - loss: 4.6110 - mean_absolute_error: 1.1435 - mean_squared_error: 4.6110\n11744/16512 [====================&gt;.........] - ETA: 0s - loss: 4.2645 - mean_absolute_error: 1.0994 - mean_squared_error: 4.2645\n12800/16512 [======================&gt;.......] - ETA: 0s - loss: 3.9780 - mean_absolute_error: 1.0653 - mean_squared_error: 3.9780\n13856/16512 [========================&gt;.....] - ETA: 0s - loss: 3.7318 - mean_absolute_error: 1.0336 - mean_squared_error: 3.7318\n14880/16512 [==========================&gt;...] - ETA: 0s - loss: 3.5327 - mean_absolute_error: 1.0106 - mean_squared_error: 3.5327\n15744/16512 [===========================&gt;..] - ETA: 0s - loss: 3.3833 - mean_absolute_error: 0.9928 - mean_squared_error: 3.3833\n16512/16512 [==============================] - 1s 49us/step - loss: 3.2682 - mean_absolute_error: 0.9796 - mean_squared_error: 3.2682\nEpoch 18/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 1.4901 - mean_absolute_error: 0.9929 - mean_squared_error: 1.4901\n 1120/16512 [=&gt;............................] - ETA: 0s - loss: 0.9768 - mean_absolute_error: 0.7554 - mean_squared_error: 0.9768\n 2208/16512 [===&gt;..........................] - ETA: 0s - loss: 0.8599 - mean_absolute_error: 0.7040 - mean_squared_error: 0.8599\n 3264/16512 [====&gt;.........................] - ETA: 0s - loss: 0.8977 - mean_absolute_error: 0.7149 - mean_squared_error: 0.8977\n 4320/16512 [======&gt;.......................] - ETA: 0s - loss: 0.8989 - mean_absolute_error: 0.7146 - mean_squared_error: 0.8989\n 5344/16512 [========&gt;.....................] - ETA: 0s - loss: 0.8997 - mean_absolute_error: 0.7166 - mean_squared_error: 0.8997\n 6368/16512 [==========&gt;...................] - ETA: 0s - loss: 1.0464 - mean_absolute_error: 0.7387 - mean_squared_error: 1.0464\n 7424/16512 [============&gt;.................] - ETA: 0s - loss: 1.2266 - mean_absolute_error: 0.7870 - mean_squared_error: 1.2266\n 8480/16512 [==============&gt;...............] - ETA: 0s - loss: 1.1787 - mean_absolute_error: 0.7772 - mean_squared_error: 1.1787\n 9568/16512 [================&gt;.............] - ETA: 0s - loss: 1.3460 - mean_absolute_error: 0.8219 - mean_squared_error: 1.3460\n10624/16512 [==================&gt;...........] - ETA: 0s - loss: 1.9216 - mean_absolute_error: 0.9313 - mean_squared_error: 1.9216\n11648/16512 [====================&gt;.........] - ETA: 0s - loss: 1.8937 - mean_absolute_error: 0.9304 - mean_squared_error: 1.8937\n12704/16512 [======================&gt;.......] - ETA: 0s - loss: 2.1704 - mean_absolute_error: 0.9862 - mean_squared_error: 2.1704\n13760/16512 [========================&gt;.....] - ETA: 0s - loss: 2.0706 - mean_absolute_error: 0.9648 - mean_squared_error: 2.0706\n14848/16512 [=========================&gt;....] - ETA: 0s - loss: 1.9826 - mean_absolute_error: 0.9447 - mean_squared_error: 1.9826\n15872/16512 [===========================&gt;..] - ETA: 0s - loss: 1.9205 - mean_absolute_error: 0.9340 - mean_squared_error: 1.9205\n16512/16512 [==============================] - 1s 48us/step - loss: 1.8787 - mean_absolute_error: 0.9256 - mean_squared_error: 1.8787\nEpoch 19/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 1.5410 - mean_absolute_error: 0.8790 - mean_squared_error: 1.5410\n 1088/16512 [&gt;.............................] - ETA: 0s - loss: 0.7691 - mean_absolute_error: 0.6742 - mean_squared_error: 0.7691\n 2112/16512 [==&gt;...........................] - ETA: 0s - loss: 0.8454 - mean_absolute_error: 0.7093 - mean_squared_error: 0.8454\n 3136/16512 [====&gt;.........................] - ETA: 0s - loss: 1.4241 - mean_absolute_error: 0.8660 - mean_squared_error: 1.4241\n 4224/16512 [======&gt;.......................] - ETA: 0s - loss: 25.5306 - mean_absolute_error: 2.4284 - mean_squared_error: 25.5306\n 5216/16512 [========&gt;.....................] - ETA: 0s - loss: 30.7504 - mean_absolute_error: 2.9604 - mean_squared_error: 30.7504\n 6304/16512 [==========&gt;...................] - ETA: 0s - loss: 27.6349 - mean_absolute_error: 2.8707 - mean_squared_error: 27.6349\n 7296/16512 [============&gt;.................] - ETA: 0s - loss: 24.3540 - mean_absolute_error: 2.6668 - mean_squared_error: 24.3540\n 8352/16512 [==============&gt;...............] - ETA: 0s - loss: 21.5178 - mean_absolute_error: 2.4570 - mean_squared_error: 21.5178\n 9376/16512 [================&gt;.............] - ETA: 0s - loss: 19.2645 - mean_absolute_error: 2.2690 - mean_squared_error: 19.2645\n10400/16512 [=================&gt;............] - ETA: 0s - loss: 17.4612 - mean_absolute_error: 2.1204 - mean_squared_error: 17.4612\n11456/16512 [===================&gt;..........] - ETA: 0s - loss: 15.9288 - mean_absolute_error: 1.9891 - mean_squared_error: 15.9288\n12512/16512 [=====================&gt;........] - ETA: 0s - loss: 14.6551 - mean_absolute_error: 1.8792 - mean_squared_error: 14.6551\n13568/16512 [=======================&gt;......] - ETA: 0s - loss: 13.5726 - mean_absolute_error: 1.7840 - mean_squared_error: 13.5726\n14592/16512 [=========================&gt;....] - ETA: 0s - loss: 12.6769 - mean_absolute_error: 1.7064 - mean_squared_error: 12.6769\n15616/16512 [===========================&gt;..] - ETA: 0s - loss: 11.8894 - mean_absolute_error: 1.6345 - mean_squared_error: 11.8894\n16512/16512 [==============================] - 1s 49us/step - loss: 11.8761 - mean_absolute_error: 1.6447 - mean_squared_error: 11.8761\nEpoch 20/20\n\n   32/16512 [..............................] - ETA: 1s - loss: 7.6870 - mean_absolute_error: 1.8162 - mean_squared_error: 7.6870\n 1088/16512 [&gt;.............................] - ETA: 0s - loss: 3.1836 - mean_absolute_error: 1.2117 - mean_squared_error: 3.1836\n 2112/16512 [==&gt;...........................] - ETA: 0s - loss: 2.4781 - mean_absolute_error: 1.1000 - mean_squared_error: 2.4781\n 2816/16512 [====&gt;.........................] - ETA: 0s - loss: 2.2409 - mean_absolute_error: 1.0541 - mean_squared_error: 2.2409\n 3840/16512 [=====&gt;........................] - ETA: 0s - loss: 1.9539 - mean_absolute_error: 0.9925 - mean_squared_error: 1.9539\n 4768/16512 [=======&gt;......................] - ETA: 0s - loss: 1.7373 - mean_absolute_error: 0.9323 - mean_squared_error: 1.7373\n 5792/16512 [=========&gt;....................] - ETA: 0s - loss: 1.6972 - mean_absolute_error: 0.9296 - mean_squared_error: 1.6972\n 6624/16512 [===========&gt;..................] - ETA: 0s - loss: 1.6273 - mean_absolute_error: 0.9135 - mean_squared_error: 1.6273\n 7680/16512 [============&gt;.................] - ETA: 0s - loss: 1.8429 - mean_absolute_error: 0.9611 - mean_squared_error: 1.8429\n 8736/16512 [==============&gt;...............] - ETA: 0s - loss: 1.8183 - mean_absolute_error: 0.9586 - mean_squared_error: 1.8183\n 9792/16512 [================&gt;.............] - ETA: 0s - loss: 1.7105 - mean_absolute_error: 0.9297 - mean_squared_error: 1.7105\n10848/16512 [==================&gt;...........] - ETA: 0s - loss: 1.6391 - mean_absolute_error: 0.9099 - mean_squared_error: 1.6391\n11904/16512 [====================&gt;.........] - ETA: 0s - loss: 1.5758 - mean_absolute_error: 0.8959 - mean_squared_error: 1.5758\n12960/16512 [======================&gt;.......] - ETA: 0s - loss: 1.5449 - mean_absolute_error: 0.8903 - mean_squared_error: 1.5449\n13984/16512 [========================&gt;.....] - ETA: 0s - loss: 1.4860 - mean_absolute_error: 0.8722 - mean_squared_error: 1.4860\n15040/16512 [==========================&gt;...] - ETA: 0s - loss: 1.4459 - mean_absolute_error: 0.8605 - mean_squared_error: 1.4459\n16096/16512 [============================&gt;.] - ETA: 0s - loss: 1.4299 - mean_absolute_error: 0.8583 - mean_squared_error: 1.4299\n16512/16512 [==============================] - 1s 51us/step - loss: 1.4220 - mean_absolute_error: 0.8567 - mean_squared_error: 1.4220\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n\ndef viewModelLoss():\n  plt.clf()\n  plt.plot(history.history['loss'])\n  plt.title('model loss')\n  plt.ylabel('loss')\n  plt.xlabel('epoch')\n  display(plt.show())\nviewModelLoss()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"image/png":["data:image/png;base64,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"]}}],"execution_count":17},{"cell_type":"markdown","source":["## 4. Batch Size\n\nLet's set our `batch_size` (how much data to be processed simultaneously by the model) to 64, and increase our `epochs` to 20. Mini-batches are often a power of 2, to facilitate memory allocation on GPU (typically between 8 and 128).\n\n\nAlso, if you don't want to see all of the intermediate values print out, you can set the `verbose` parameter: 0 = silent, 1 = progress bar, 2 = one line per epoch (defaults to 1)"],"metadata":{}},{"cell_type":"code","source":["loss"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">9</span><span class=\"ansired\">]: </span>&apos;mse&apos;\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["model = build_model()\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\nhistory = model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Epoch 1/20\n - 1s - loss: 237.9879 - mean_absolute_error: 4.5829 - mean_squared_error: 237.9879\nEpoch 2/20\n - 1s - loss: 3.3341 - mean_absolute_error: 1.0322 - mean_squared_error: 3.3341\nEpoch 3/20\n - 1s - loss: 1.2129 - mean_absolute_error: 0.8540 - mean_squared_error: 1.2129\nEpoch 4/20\n - 1s - loss: 1.1065 - mean_absolute_error: 0.8307 - mean_squared_error: 1.1065\nEpoch 5/20\n - 1s - loss: 1.1306 - mean_absolute_error: 0.8396 - mean_squared_error: 1.1306\nEpoch 6/20\n - 1s - loss: 4.6322 - mean_absolute_error: 1.2816 - mean_squared_error: 4.6322\nEpoch 7/20\n - 1s - loss: 13.3712 - mean_absolute_error: 1.5541 - mean_squared_error: 13.3712\nEpoch 8/20\n - 1s - loss: 1.6697 - mean_absolute_error: 0.9285 - mean_squared_error: 1.6697\nEpoch 9/20\n - 1s - loss: 1.4451 - mean_absolute_error: 0.9203 - mean_squared_error: 1.4451\nEpoch 10/20\n - 1s - loss: 41.0714 - mean_absolute_error: 2.4201 - mean_squared_error: 41.0714\nEpoch 11/20\n - 1s - loss: 1.0174 - mean_absolute_error: 0.7803 - mean_squared_error: 1.0174\nEpoch 12/20\n - 1s - loss: 1.1815 - mean_absolute_error: 0.7984 - mean_squared_error: 1.1815\nEpoch 13/20\n - 1s - loss: 6.0780 - mean_absolute_error: 1.3663 - mean_squared_error: 6.0780\nEpoch 14/20\n - 1s - loss: 46.9945 - mean_absolute_error: 2.1754 - mean_squared_error: 46.9945\nEpoch 15/20\n - 1s - loss: 1.1356 - mean_absolute_error: 0.7812 - mean_squared_error: 1.1356\nEpoch 16/20\n - 1s - loss: 1.2401 - mean_absolute_error: 0.8001 - mean_squared_error: 1.2401\nEpoch 17/20\n - 1s - loss: 2.4359 - mean_absolute_error: 1.0310 - mean_squared_error: 2.4359\nEpoch 18/20\n - 1s - loss: 3.8200 - mean_absolute_error: 1.1068 - mean_squared_error: 3.8200\nEpoch 19/20\n - 1s - loss: 2.3898 - mean_absolute_error: 1.0374 - mean_squared_error: 2.3898\nEpoch 20/20\n - 1s - loss: 24.1889 - mean_absolute_error: 2.3303 - mean_squared_error: 24.1889\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["# Change the batch size to 32, and notice how choppy it is!"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["-sandbox\n&copy; 2018 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"01a Intro to Keras II","notebookId":1257123},"nbformat":4,"nbformat_minor":0}
