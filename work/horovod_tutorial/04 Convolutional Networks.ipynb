{"cells":[{"cell_type":"markdown","source":["-sandbox\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["#Convolutional Neural Networks\n\nWe will use pre-trained Convolutional Neural Networks (CNNs), trained with the image dataset from [ImageNet](http://www.image-net.org/), to demonstrate two aspects. First, how to explore and classify images. And second, how to use transfer learning with existing trained models (next lab)."],"metadata":{}},{"cell_type":"markdown","source":["## VGG16\n![vgg16](https://brookewenig.github.io/img/DL/vgg16.png)\n\nWe are going to start with the VGG16 model, which was introduced by Simonyan and Zisserman in their 2014 paper [Very Deep Convolutional Networks for Large Scale Image Recognition](https://arxiv.org/abs/1409.1556).\n\nLet's start by downloading VGG's weights and model architecture."],"metadata":{}},{"cell_type":"code","source":["from keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions, VGG16\nimport numpy as np\nimport os\n\nvgg16Model = VGG16(weights='imagenet')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from &#96;float&#96; to &#96;np.floating&#96; is deprecated. In future, it will be treated as &#96;np.float64 == np.dtype(float).type&#96;.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\nDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n\n     8192/553467096 [..............................] - ETA: 1:29:57\n    40960/553467096 [..............................] - ETA: 36:14  \n    90112/553467096 [..............................] - ETA: 24:43\n   212992/553467096 [..............................] - ETA: 13:58\n   442368/553467096 [..............................] - ETA: 8:24 \n   892928/553467096 [..............................] - ETA: 4:59\n  1810432/553467096 [..............................] - ETA: 2:52\n  3555328/553467096 [..............................] - ETA: 1:39\n  5980160/553467096 [..............................] - ETA: 1:07\n  8339456/553467096 [..............................] - ETA: 53s \n 10600448/553467096 [..............................] - ETA: 46s\n 12746752/553467096 [..............................] - ETA: 41s\n 14794752/553467096 [..............................] - ETA: 38s\n 16728064/553467096 [..............................] - ETA: 36s\n 18989056/553467096 [&gt;.............................] - ETA: 34s\n 21266432/553467096 [&gt;.............................] - ETA: 32s\n 23298048/553467096 [&gt;.............................] - ETA: 31s\n 25378816/553467096 [&gt;.............................] - ETA: 30s\n 27541504/553467096 [&gt;.............................] - ETA: 29s\n 29802496/553467096 [&gt;.............................] - ETA: 28s\n 32325632/553467096 [&gt;.............................] - ETA: 27s\n 34177024/553467096 [&gt;.............................] - ETA: 27s\n 36519936/553467096 [&gt;.............................] - ETA: 26s\n 38600704/553467096 [=&gt;............................] - ETA: 26s\n 40665088/553467096 [=&gt;............................] - ETA: 25s\n 43204608/553467096 [=&gt;............................] - ETA: 25s\n 45219840/553467096 [=&gt;............................] - ETA: 25s\n 47661056/553467096 [=&gt;............................] - ETA: 24s\n 49463296/553467096 [=&gt;............................] - ETA: 24s\n 51527680/553467096 [=&gt;............................] - ETA: 24s\n 53985280/553467096 [=&gt;............................] - ETA: 23s\n 55902208/553467096 [==&gt;...........................] - ETA: 23s\n 58261504/553467096 [==&gt;...........................] - ETA: 23s\n 60473344/553467096 [==&gt;...........................] - ETA: 22s\n 62914560/553467096 [==&gt;...........................] - ETA: 22s\n 64995328/553467096 [==&gt;...........................] - ETA: 22s\n 65011712/553467096 [==&gt;...........................] - ETA: 22s\n 67010560/553467096 [==&gt;...........................] - ETA: 22s\n 69533696/553467096 [==&gt;...........................] - ETA: 21s\n 71368704/553467096 [==&gt;...........................] - ETA: 21s\n 73695232/553467096 [==&gt;...........................] - ETA: 21s\n 75128832/553467096 [===&gt;..........................] - ETA: 21s\n 76480512/553467096 [===&gt;..........................] - ETA: 21s\n 78168064/553467096 [===&gt;..........................] - ETA: 21s\n 80363520/553467096 [===&gt;..........................] - ETA: 20s\n 82575360/553467096 [===&gt;..........................] - ETA: 20s\n 84590592/553467096 [===&gt;..........................] - ETA: 20s\n 86687744/553467096 [===&gt;..........................] - ETA: 20s\n 88408064/553467096 [===&gt;..........................] - ETA: 20s\n 89669632/553467096 [===&gt;..........................] - ETA: 20s\n 91144192/553467096 [===&gt;..........................] - ETA: 20s\n 91701248/553467096 [===&gt;..........................] - ETA: 20s\n 93667328/553467096 [====&gt;.........................] - ETA: 20s\n 96043008/553467096 [====&gt;.........................] - ETA: 19s\n 97566720/553467096 [====&gt;.........................] - ETA: 19s\n 98729984/553467096 [====&gt;.........................] - ETA: 19s\n100270080/553467096 [====&gt;.........................] - ETA: 19s\n102514688/553467096 [====&gt;.........................] - ETA: 19s\n104906752/553467096 [====&gt;.........................] - ETA: 19s\n106397696/553467096 [====&gt;.........................] - ETA: 18s\n107610112/553467096 [====&gt;.........................] - ETA: 18s\n109805568/553467096 [====&gt;.........................] - ETA: 18s\n110968832/553467096 [=====&gt;........................] - ETA: 18s\n112328704/553467096 [=====&gt;........................] - ETA: 18s\n114835456/553467096 [=====&gt;........................] - ETA: 18s\n117325824/553467096 [=====&gt;........................] - ETA: 18s\n118865920/553467096 [=====&gt;........................] - ETA: 18s\n120995840/553467096 [=====&gt;........................] - ETA: 17s\n122290176/553467096 [=====&gt;........................] - ETA: 17s\n123781120/553467096 [=====&gt;........................] - ETA: 17s\n125796352/553467096 [=====&gt;........................] - ETA: 17s\n127156224/553467096 [=====&gt;........................] - ETA: 17s\n128819200/553467096 [=====&gt;........................] - ETA: 17s\n130088960/553467096 [======&gt;.......................] - ETA: 17s\n132169728/553467096 [======&gt;.......................] - ETA: 17s\n134692864/553467096 [======&gt;.......................] - ETA: 17s\n137134080/553467096 [======&gt;.......................] - ETA: 17s\n138985472/553467096 [======&gt;.......................] - ETA: 17s\n141131776/553467096 [======&gt;.......................] - ETA: 16s\n142606336/553467096 [======&gt;.......................] - ETA: 16s\n143671296/553467096 [======&gt;.......................] - ETA: 16s\n146145280/553467096 [======&gt;.......................] - ETA: 16s\n148619264/553467096 [=======&gt;......................] - ETA: 16s\n151191552/553467096 [=======&gt;......................] - ETA: 16s\n153632768/553467096 [=======&gt;......................] - ETA: 16s\n156172288/553467096 [=======&gt;......................] - ETA: 16s\n158695424/553467096 [=======&gt;......................] - ETA: 15s\n160956416/553467096 [=======&gt;......................] - ETA: 15s\n163414016/553467096 [=======&gt;......................] - ETA: 15s\n165888000/553467096 [=======&gt;......................] - ETA: 15s\n168165376/553467096 [========&gt;.....................] - ETA: 15s\n169836544/553467096 [========&gt;.....................] - ETA: 15s\n170795008/553467096 [========&gt;.....................] - ETA: 15s\n173228032/553467096 [========&gt;.....................] - ETA: 15s\n175554560/553467096 [========&gt;.....................] - ETA: 15s\n177979392/553467096 [========&gt;.....................] - ETA: 14s\n180502528/553467096 [========&gt;.....................] - ETA: 14s\n183025664/553467096 [========&gt;.....................] - ETA: 14s\n185409536/553467096 [=========&gt;....................] - ETA: 14s\n186515456/553467096 [=========&gt;....................] - ETA: 14s\n188055552/553467096 [=========&gt;....................] - ETA: 14s\n190267392/553467096 [=========&gt;....................] - ETA: 14s\n191594496/553467096 [=========&gt;....................] - ETA: 14s\n193101824/553467096 [=========&gt;....................] - ETA: 14s\n195215360/553467096 [=========&gt;....................] - ETA: 14s\n197083136/553467096 [=========&gt;....................] - ETA: 13s\n198836224/553467096 [=========&gt;....................] - ETA: 13s\n200327168/553467096 [=========&gt;....................] - ETA: 13s\n202637312/553467096 [=========&gt;....................] - ETA: 13s\n203751424/553467096 [==========&gt;...................] - ETA: 13s\n205012992/553467096 [==========&gt;...................] - ETA: 13s\n206422016/553467096 [==========&gt;...................] - ETA: 13s\n208289792/553467096 [==========&gt;...................] - ETA: 13s\n209813504/553467096 [==========&gt;...................] - ETA: 13s\n211271680/553467096 [==========&gt;...................] - ETA: 13s\n212533248/553467096 [==========&gt;...................] - ETA: 13s\n214761472/553467096 [==========&gt;...................] - ETA: 13s\n216612864/553467096 [==========&gt;...................] - ETA: 13s\n218431488/553467096 [==========&gt;...................] - ETA: 12s\n219693056/553467096 [==========&gt;...................] - ETA: 12s\n220971008/553467096 [==========&gt;...................] - ETA: 12s\n222437376/553467096 [===========&gt;..................] - ETA: 12s\n224231424/553467096 [===========&gt;..................] - ETA: 12s\n225935360/553467096 [===========&gt;..................] - ETA: 12s\n228081664/553467096 [===========&gt;..................] - ETA: 12s\n229687296/553467096 [===========&gt;..................] - ETA: 12s\n230998016/553467096 [===========&gt;..................] - ETA: 12s\n232603648/553467096 [===========&gt;..................] - ETA: 12s\n234618880/553467096 [===========&gt;..................] - ETA: 12s\n236257280/553467096 [===========&gt;..................] - ETA: 12s\n238436352/553467096 [===========&gt;..................] - ETA: 12s\n240517120/553467096 [============&gt;.................] - ETA: 11s\n241975296/553467096 [============&gt;.................] - ETA: 11s\n243367936/553467096 [============&gt;.................] - ETA: 11s\n244940800/553467096 [============&gt;.................] - ETA: 11s\n247021568/553467096 [============&gt;.................] - ETA: 11s\n248709120/553467096 [============&gt;.................] - ETA: 11s\n250707968/553467096 [============&gt;.................] - ETA: 11s\n252051456/553467096 [============&gt;.................] - ETA: 11s\n253452288/553467096 [============&gt;.................] - ETA: 11s\n255336448/553467096 [============&gt;.................] - ETA: 11s\n256933888/553467096 [============&gt;.................] - ETA: 11s\n258416640/553467096 [=============&gt;................] - ETA: 11s\n260243456/553467096 [=============&gt;................] - ETA: 11s\n261881856/553467096 [=============&gt;................] - ETA: 11s\n263356416/553467096 [=============&gt;................] - ETA: 11s\n265519104/553467096 [=============&gt;................] - ETA: 10s\n266878976/553467096 [=============&gt;................] - ETA: 10s\n268148736/553467096 [=============&gt;................] - ETA: 10s\n270516224/553467096 [=============&gt;................] - ETA: 10s\n273039360/553467096 [=============&gt;................] - ETA: 10s\n275513344/553467096 [=============&gt;................] - ETA: 10s\n278036480/553467096 [==============&gt;...............] - ETA: 10s\n280576000/553467096 [==============&gt;...............] - ETA: 10s\n283000832/553467096 [==============&gt;...............] - ETA: 10s\n284590080/553467096 [==============&gt;...............] - ETA: 10s\n285564928/553467096 [==============&gt;...............] - ETA: 10s\n287916032/553467096 [==============&gt;...............] - ETA: 10s\n289275904/553467096 [==============&gt;...............] - ETA: 9s \n290553856/553467096 [==============&gt;...............] - ETA: 9s\n292945920/553467096 [==============&gt;...............] - ETA: 9s\n295436288/553467096 [===============&gt;..............] - ETA: 9s\n297721856/553467096 [===============&gt;..............] - ETA: 9s\n298237952/553467096 [===============&gt;..............] - ETA: 9s\n300417024/553467096 [===============&gt;..............] - ETA: 9s\n301842432/553467096 [===============&gt;..............] - ETA: 9s\n302940160/553467096 [===============&gt;..............] - ETA: 9s\n305463296/553467096 [===============&gt;..............] - ETA: 9s\n307871744/553467096 [===============&gt;..............] - ETA: 9s\n310247424/553467096 [===============&gt;..............] - ETA: 9s\n312786944/553467096 [===============&gt;..............] - ETA: 9s\n315310080/553467096 [================&gt;.............] - ETA: 8s\n317669376/553467096 [================&gt;.............] - ETA: 8s\n320143360/553467096 [================&gt;.............] - ETA: 8s\n322650112/553467096 [================&gt;.............] - ETA: 8s\n324476928/553467096 [================&gt;.............] - ETA: 8s\n325189632/553467096 [================&gt;.............] - ETA: 8s\n327663616/553467096 [================&gt;.............] - ETA: 8s\n330153984/553467096 [================&gt;.............] - ETA: 8s\n332578816/553467096 [=================&gt;............] - ETA: 8s\n334364672/553467096 [=================&gt;............] - ETA: 8s\n335101952/553467096 [=================&gt;............] - ETA: 8s\n337625088/553467096 [=================&gt;............] - ETA: 8s\n339984384/553467096 [=================&gt;............] - ETA: 7s\n342376448/553467096 [=================&gt;............] - ETA: 7s\n344915968/553467096 [=================&gt;............] - ETA: 7s\n347389952/553467096 [=================&gt;............] - ETA: 7s\n349913088/553467096 [=================&gt;............] - ETA: 7s\n352223232/553467096 [==================&gt;...........] - ETA: 7s\n354697216/553467096 [==================&gt;...........] - ETA: 7s\n357171200/553467096 [==================&gt;...........] - ETA: 7s\n359088128/553467096 [==================&gt;...........] - ETA: 7s\n359759872/553467096 [==================&gt;...........] - ETA: 7s\n362217472/553467096 [==================&gt;...........] - ETA: 7s\n364642304/553467096 [==================&gt;...........] - ETA: 7s\n366772224/553467096 [==================&gt;...........] - ETA: 6s\n367165440/553467096 [==================&gt;...........] - ETA: 6s\n369557504/553467096 [===================&gt;..........] - ETA: 6s\n372080640/553467096 [===================&gt;..........] - ETA: 6s\n374538240/553467096 [===================&gt;..........] - ETA: 6s\n376930304/553467096 [===================&gt;..........] - ETA: 6s\n379469824/553467096 [===================&gt;..........] - ETA: 6s\n381878272/553467096 [===================&gt;..........] - ETA: 6s\n384417792/553467096 [===================&gt;..........] - ETA: 6s\n386875392/553467096 [===================&gt;..........] - ETA: 6s\n389414912/553467096 [====================&gt;.........] - ETA: 6s\n391774208/553467096 [====================&gt;.........] - ETA: 5s\n394313728/553467096 [====================&gt;.........] - ETA: 5s\n396836864/553467096 [====================&gt;.........] - ETA: 5s\n399007744/553467096 [====================&gt;.........] - ETA: 5s\n400343040/553467096 [====================&gt;.........] - ETA: 5s\n402046976/553467096 [====================&gt;.........] - ETA: 5s\n404307968/553467096 [====================&gt;.........] - ETA: 5s\n405372928/553467096 [====================&gt;.........] - ETA: 5s\n407879680/553467096 [=====================&gt;........] - ETA: 5s\n410361856/553467096 [=====================&gt;........] - ETA: 5s\n411402240/553467096 [=====================&gt;........] - ETA: 5s\n412680192/553467096 [=====================&gt;........] - ETA: 5s\n414113792/553467096 [=====================&gt;........] - ETA: 5s\n415588352/553467096 [=====================&gt;........] - ETA: 5s\n417595392/553467096 [=====================&gt;........] - ETA: 4s\n419594240/553467096 [=====================&gt;........] - ETA: 4s\n421199872/553467096 [=====================&gt;........] - ETA: 4s\n422641664/553467096 [=====================&gt;........] - ETA: 4s\n424001536/553467096 [=====================&gt;........] - ETA: 4s\n426196992/553467096 [======================&gt;.......] - ETA: 4s\n428572672/553467096 [======================&gt;.......] - ETA: 4s\n429785088/553467096 [======================&gt;.......] - ETA: 4s\n431292416/553467096 [======================&gt;.......] - ETA: 4s\n433569792/553467096 [======================&gt;.......] - ETA: 4s\n435494912/553467096 [======================&gt;.......] - ETA: 4s\n437141504/553467096 [======================&gt;.......] - ETA: 4s\n439386112/553467096 [======================&gt;.......] - ETA: 4s\n440893440/553467096 [======================&gt;.......] - ETA: 4s\n442187776/553467096 [======================&gt;.......] - ETA: 4s\n444514304/553467096 [=======================&gt;......] - ETA: 3s\n445939712/553467096 [=======================&gt;......] - ETA: 3s\n447283200/553467096 [=======================&gt;......] - ETA: 3s\n449478656/553467096 [=======================&gt;......] - ETA: 3s\n450887680/553467096 [=======================&gt;......] - ETA: 3s\n452067328/553467096 [=======================&gt;......] - ETA: 3s\n454524928/553467096 [=======================&gt;......] - ETA: 3s\n457064448/553467096 [=======================&gt;......] - ETA: 3s\n459538432/553467096 [=======================&gt;......] - ETA: 3s\n461398016/553467096 [========================&gt;.....] - ETA: 3s\n463077376/553467096 [========================&gt;.....] - ETA: 3s\n464551936/553467096 [========================&gt;.....] - ETA: 3s\n466845696/553467096 [========================&gt;.....] - ETA: 3s\n468123648/553467096 [========================&gt;.....] - ETA: 3s\n469434368/553467096 [========================&gt;.....] - ETA: 3s\n471678976/553467096 [========================&gt;.....] - ETA: 2s\n474185728/553467096 [========================&gt;.....] - ETA: 2s\n476332032/553467096 [========================&gt;.....] - ETA: 2s\n477233152/553467096 [========================&gt;.....] - ETA: 2s\n479166464/553467096 [========================&gt;.....] - ETA: 2s\n481607680/553467096 [=========================&gt;....] - ETA: 2s\n484065280/553467096 [=========================&gt;....] - ETA: 2s\n485736448/553467096 [=========================&gt;....] - ETA: 2s\n486793216/553467096 [=========================&gt;....] - ETA: 2s\n489078784/553467096 [=========================&gt;....] - ETA: 2s\n491241472/553467096 [=========================&gt;....] - ETA: 2s\n492699648/553467096 [=========================&gt;....] - ETA: 2s\n494215168/553467096 [=========================&gt;....] - ETA: 2s\n496386048/553467096 [=========================&gt;....] - ETA: 2s\n497852416/553467096 [=========================&gt;....] - ETA: 2s\n499286016/553467096 [==========================&gt;...] - ETA: 1s\n501252096/553467096 [==========================&gt;...] - ETA: 1s\n502726656/553467096 [==========================&gt;...] - ETA: 1s\n503898112/553467096 [==========================&gt;...] - ETA: 1s\n506331136/553467096 [==========================&gt;...] - ETA: 1s\n508739584/553467096 [==========================&gt;...] - ETA: 1s\n510427136/553467096 [==========================&gt;...] - ETA: 1s\n512327680/553467096 [==========================&gt;...] - ETA: 1s\n513785856/553467096 [==========================&gt;...] - ETA: 1s\n516227072/553467096 [==========================&gt;...] - ETA: 1s\n517750784/553467096 [===========================&gt;..] - ETA: 1s\n519913472/553467096 [===========================&gt;..] - ETA: 1s\n521494528/553467096 [===========================&gt;..] - ETA: 1s\n523534336/553467096 [===========================&gt;..] - ETA: 1s\n524992512/553467096 [===========================&gt;..] - ETA: 1s\n526180352/553467096 [===========================&gt;..] - ETA: 0s\n528400384/553467096 [===========================&gt;..] - ETA: 0s\n529678336/553467096 [===========================&gt;..] - ETA: 0s\n530923520/553467096 [===========================&gt;..] - ETA: 0s\n533446656/553467096 [===========================&gt;..] - ETA: 0s\n535953408/553467096 [============================&gt;.] - ETA: 0s\n538329088/553467096 [============================&gt;.] - ETA: 0s\n540590080/553467096 [============================&gt;.] - ETA: 0s\n541933568/553467096 [============================&gt;.] - ETA: 0s\n543129600/553467096 [============================&gt;.] - ETA: 0s\n544571392/553467096 [============================&gt;.] - ETA: 0s\n545726464/553467096 [============================&gt;.] - ETA: 0s\n548192256/553467096 [============================&gt;.] - ETA: 0s\n550748160/553467096 [============================&gt;.] - ETA: 0s\n553254912/553467096 [============================&gt;.] - ETA: 0s\n553467904/553467096 [==============================] - 20s 0us/step\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["We can look at the model summary. Look at how many parameters there are! Imagine if you had to train all 138,357,544 parameters from scratch! This is one motivation for re-using existing model weights.\n\n**RECAP**: What is a convolution? Max pooling?"],"metadata":{}},{"cell_type":"code","source":["vgg16Model.summary()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 224, 224, 3)       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\nfc2 (Dense)                  (None, 4096)              16781312  \n_________________________________________________________________\npredictions (Dense)          (None, 1000)              4097000   \n=================================================================\nTotal params: 138,357,544\nTrainable params: 138,357,544\nNon-trainable params: 0\n_________________________________________________________________\n</div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["**Question**: What do the input and output shapes represent?"],"metadata":{}},{"cell_type":"markdown","source":["In Tensorflow, it represents the images in a channels-last manner: (samples, height, width, color_depth)\n\nBut in other frameworks, such as Theano, the same data would be represented channels-first: (samples, color_depth, height, width)"],"metadata":{}},{"cell_type":"markdown","source":["## Apply pre-trained model\n\nWe are going to make a helper method to resize our images to be 224 x 224, and output the top 3 classes for a given image."],"metadata":{}},{"cell_type":"code","source":["def predict_images(images, model):\n  for i in images:\n    print ('processing image:', i)\n    img = image.load_img(i, target_size=(224, 224))\n    #convert to numpy array for Keras image formate processing\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = preprocess_input(x)\n    preds = model.predict(x)\n    # decode the results into a list of tuples (class, description, probability\n    print('Predicted:', decode_predictions(preds, top=3)[0], '\\n')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["-sandbox\n## Images\n<div style=\"text-align: left; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://brookewenig.github.io/img/DL/pug.jpg\" height=\"150\" width=\"150\" alt=\"Databricks Nerds!\" style=>\n  <img src=\"https://brookewenig.github.io/img/DL/strawberries.jpg\" height=\"150\" width=\"150\" alt=\"Databricks Nerds!\" style=>\n  <img src=\"https://brookewenig.github.io/img/DL/rose.jpg\" height=\"150\" width=\"150\" alt=\"Databricks Nerds!\" style=>\n  \n</div>\n\nLet's make sure the datasets are already mounted."],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom Setup\""],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["img_paths = [\"/dbfs/mnt/training/dl/img/pug.jpg\", \"/dbfs/mnt/training/dl/img/strawberries.jpg\", \"/dbfs/mnt/training/dl/img/rose.jpg\"]\npredict_images(img_paths, vgg16Model)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["The network did so well with the pug and strawberry! What happened with the rose? Well, it turns out that `rose` was not one of the 1000 categories that VGG16 had to predict. But it is quite interesting it predicted `sea_anemone` and `vase`."],"metadata":{}},{"cell_type":"markdown","source":["You can play around with this with your own images by doing the following:\n\nGet a new file: \n\n`%sh wget image_url.jpg`\n\n`%fs cp file:/databricks/driver/image_name.jpg yourName/tmp/image_name.jpg `\n\n\nOR\n\nYou can upload this file via the Data UI and read in from the FileStore path (e.g. `/dbfs/FileStore/image_name.jpg`)."],"metadata":{}},{"cell_type":"markdown","source":["# DeepImagePredictor\n\nWhile it's great and fun to play around with Keras on the driver, what about loading a copy of the model to our workers, and make these predictions in parallel on our Spark cluster using [Deep Learning Pipelines](https://github.com/databricks/spark-deep-learning)! \n\nDeep Learning Pipelines is an open-source project started by Databricks for distributed model inference of deep learning models.\n\n**NOTE**: We are running it on a small dataset, and there is quite high overhead of copying the model to our workers. This is useful when your datasets are quite large"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n## Classify Co-Founders of Databricks\n<div style=\"text-align: left; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2017/12/Ali-Ghodsi-4.jpg\" height=\"150\" width=\"150\" alt=\"Databricks Nerds!\" style=>\n  <img src=\"https://databricks.com/wp-content/uploads/2017/12/andy-konwinski-1.jpg\" height=\"150\" width=\"150\" alt=\"Databricks Nerds!\" style=>\n  <img src=\"https://databricks.com/wp-content/uploads/2015/08/ionS.jpg\" height=\"150\" width=\"150\" alt=\"Databricks Nerds!\" style=>\n  <img src=\"https://databricks.com/wp-content/uploads/2016/02/MateiZ.jpg\" height=\"200\" width=\"150\" alt=\"Databricks Nerds!\" style=>\n  <img src=\"https://databricks.com/wp-content/uploads/2015/08/patrickW.jpg\" height=\"150\" width=\"150\" alt=\"Databricks Nerds!\" style=>\n  <img src=\"https://databricks.com/wp-content/uploads/2017/12/Reynold-Xin.jpg\" height=\"150\" width=\"150\" alt=\"Databricks Nerds!\" style=>\n</div>"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.image import ImageSchema\nfrom sparkdl.image import imageIO\nfrom sparkdl import DeepImagePredictor\n\ndf = ImageSchema.readImages(\"mnt/training/dl/img/founders/\")\n\npredictor = DeepImagePredictor(inputCol=\"image\", outputCol=\"predicted_labels\", modelName=\"VGG16\", decodePredictions=True, topK=5)\npredictions_df = predictor.transform(df).cache()\ndisplay(predictions_df)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["## Inception V3\n\nWhat happened to Matei's predictions: Chain mail?? Well, he truly is Spark's knight in shining armor!\n\nLet's change the model to a more recent architecture, and see what the predictions are now!"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.image import ImageSchema\nfrom sparkdl.image import imageIO\nfrom sparkdl import DeepImagePredictor\n\ndf = ImageSchema.readImages(\"mnt/training/dl/img/founders/\")\n\npredictor = DeepImagePredictor(inputCol=\"image\", outputCol=\"predicted_labels\", modelName=\"InceptionV3\", decodePredictions=True, topK=5)\npredictions_df = predictor.transform(df).cache()\ndisplay(predictions_df)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["Yikes! These are not the most natural predictions (because ImageNet did not have a `person` category). In the next lab, we will cover how to utilize existing components of the VGG16 architecture, and how to retrain the final classifier."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2018 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"04 Convolutional Networks","notebookId":1257146},"nbformat":4,"nbformat_minor":0}
