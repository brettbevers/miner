{"cells":[{"cell_type":"markdown","source":["-sandbox\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["## Horovod Lab\n\nIn this notebook, we are going to take the Boston Dataset that we were working with earlier, but change it to train across the cluster, instead of just on the driver.\n\nLet's start by reading in the data, and converting it to a Spark DataFrame."],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.sql.functions import *\nfrom tensorflow import keras \n\n(x_train, y_train), (x_test, y_test) = keras.datasets.boston_housing.load_data()\n\npdTrain = pd.concat([pd.DataFrame(x_train), pd.DataFrame(y_train, columns=[\"label\"])], axis=1)\npdTest = pd.concat([pd.DataFrame(x_test), pd.DataFrame(y_test, columns=[\"label\"])], axis=1)\n\ntrainDF = spark.createDataFrame(pdTrain)\ntestDF = spark.createDataFrame(pdTest)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["## Types\n\nThere are a few limitations with the current implementation of Horovod. One of them is that the datatypes have to be of float type, and for inference, it needs to be an array type instead of a Vector. We have already done those transformations for you below."],"metadata":{}},{"cell_type":"code","source":["trainDF = trainDF.select([col(c).cast(\"float\") for c in trainDF.columns])\ntestDF = testDF.select([col(c).cast(\"float\") for c in testDF.columns]) \n# Must to train on float datatype (if use VectorAssembler, automatically does the conversion), but label needs to be converted too\n\nvec = VectorAssembler(inputCols=trainDF.columns[:-1], outputCol=\"features\")\ntrainDF = (vec.transform(trainDF)\n           .select(\"features\", \"label\")\n           .withColumn(\"isVal\", when(rand() > 0.8, True).otherwise(False)))\n\n# If want inference to work, must use Array instead of Vector type\ntestDF = testDF.select(array(\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\").alias(\"features\"), \"label\") "],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["## Model_fn\n\nCreate the model_fn below. You have 2 options:\n* Write the model_fn directly in Tensorflow\n* Use a pre-made estimator from Tensorflow, and extract the model_fn\n\nYour model should be a regression model, with 50 and 20 hidden units. They should use `relu` as the activation function."],"metadata":{}},{"cell_type":"code","source":["from sparkdl.estimators.horovod_estimator.estimator import HorovodEstimator\n\nhelp(HorovodEstimator)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# ANSWER\n\nimport horovod.tensorflow as hvd  \nimport tensorflow as tf\n\ntf.set_random_seed(seed=42)\n\ndef model_fn(features, labels, mode, params, config):\n    feat_cols = [tf.feature_column.numeric_column(key=\"features\", shape=(13,))]\n    regressor = tf.estimator.DNNRegressor(hidden_units=[50, 20],\n                                          feature_columns=feat_cols,\n                                          optimizer=hvd.DistributedOptimizer(tf.train.AdamOptimizer(.001)))\n    estimator_spec = regressor.model_fn(features, labels, mode, config)\n    export_outputs = estimator_spec.export_outputs\n    if export_outputs is not None:\n        export_outputs[tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY] = export_outputs[\"predict\"]\n    return tf.estimator.EstimatorSpec(mode=mode, loss=estimator_spec.loss, train_op=estimator_spec.train_op,\n                                      export_outputs=export_outputs, training_hooks=estimator_spec.training_hooks, predictions=estimator_spec.predictions)\n  \n  \n# NOT RECOMMENDED BY ENGINEERING! USE AT YOUR OWN RISK.\n# def model_fn(features, labels, mode, params, config):\n#     model = keras.models.Sequential()\n#     features[\"features_input\"] = tf.reshape(features[\"features_input\"], [-1, 13]) # Explicitly specify dimensions\n    \n#     model.add(keras.layers.Dense(50, input_dim=13, activation=\"relu\", name=\"features\"))\n#     model.add(keras.layers.Dense(20, activation=\"relu\"))\n#     model.add(keras.layers.Dense(1, name=\"prediction\"))\n    \n#     optimizer = horovod.tensorflow.DistributedOptimizer(tf.train.AdamOptimizer(learning_rate=0.001))\n#     model.compile(optimizer=optimizer, loss='mse', metric=[\"mse\"])\n#     # Convert Keras model to a tf.estimator, then apply the resulting estimator's model function to our data\n#     # We have to create the keras model & perform the conversion to tf.estimator within model_fn as tf_est.model_fn is not picklable\n#     tf_est = tf.keras.estimator.model_to_estimator(keras_model=model)\n#     return tf_est.model_fn(features, labels, mode, params)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## HorovodEstimator\n\nCreate a HorovodEstimator. You need to specify `modelFn`, `featureMapping`, `modelDir` `labelCol`, `batchSize`, `maxSteps`, `isValidationCol`, and you can optionally specify         `saveCheckpointsSecs`.\n\nSet `batchSize`=64, and `maxSteps`=100 to start off with."],"metadata":{}},{"cell_type":"code","source":["# Create Model Directory\nimport time\nmodel_dir = \"/tmp/horovodDemo/\" + str(int(time.time())) # Have to use local path\nprint(model_dir)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# ANSWER\n\nest = HorovodEstimator(modelFn=model_fn,\n                       featureMapping={\"features\":\"features\"},\n                       modelDir=model_dir,\n                       labelCol=\"label\",\n                       batchSize=64,\n                       maxSteps=100,\n                       isValidationCol=\"isVal\",                       \n                       saveCheckpointsSecs=30)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["transformer = est.fit(trainDF)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["res = transformer.transform(testDF)\ndisplay(res)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["## Extract Predictions and Evaluate"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import FloatType\n\ndef _getPrediction(v): # Need to get element out of list to do RMSE below\n  return float(v[0])\ngetPrediction = udf(_getPrediction, FloatType())\n\npredDF = res.select(getPrediction(\"predictions\").alias(\"prediction\"), \"label\")\ndisplay(predDF)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n\nregEval = RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='mse')\n\nregEval.evaluate(predDF)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["## Improve\n\nGo back and modify the model_fn, or the HorovodEstimator parameters to reduce your MSE!"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2018 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"05a Horovod Lab","notebookId":1256643},"nbformat":4,"nbformat_minor":0}
