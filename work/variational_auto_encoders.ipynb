{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from itertools import islice\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from hyperspherical_vae.distributions import VonMisesFisher, HypersphericalUniform\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(*dfs):\n",
    "  dataset = reduce(lambda a,b: np.append(a, b, axis=0), dfs)\n",
    "  permutation = np.random.permutation(dataset.shape[0])\n",
    "  shuffled = dataset[permutation]\n",
    "  return shuffled\n",
    "\n",
    "\n",
    "unit = 0.15\n",
    "\n",
    "on = unit * 0.1\n",
    "off = unit * 0.00\n",
    "\n",
    "\n",
    "def generate_cluster(unit, cross_cov, mu, count):\n",
    "    mu = np.array(mu)\n",
    "    sigma_1, sigma_2, sigma_3 = unit, unit, unit\n",
    "    sigma_1_2, sigma_1_3, sigma_2_3 = cross_cov\n",
    "    cov = np.array([\n",
    "      [sigma_1, sigma_1_2, sigma_1_3],\n",
    "      [sigma_1_2, sigma_2, sigma_2_3],\n",
    "      [sigma_1_3, sigma_2_3, sigma_3]\n",
    "    ])\n",
    "    ds = np.random.multivariate_normal(mu, cov, count)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def reduce_correlation(ds, noise):\n",
    "    count = ds.shape[0]\n",
    "    ds_t = ds.T\n",
    "    for i, x in enumerate(noise):\n",
    "        num = int(count*x)\n",
    "        ds_t[i].put(np.random.choice(count, num, replace=False), np.random.choice(ds.T[i], num))\n",
    "    return ds_t.T\n",
    "\n",
    "\n",
    "rv1 = generate_cluster(unit, (on, -off, off), [2,0,0], 250000) \n",
    "rv2 = generate_cluster(unit, (on, off, -off), [0,0,2], 500000)\n",
    "rv3 = generate_cluster(unit, (-on, off, off), [0,2,0], 500000)\n",
    "rv4 = generate_cluster(unit, (-on, -off, -off), [-1,-1,-1], 1000000)\n",
    "\n",
    "# rv5 = generate_cluster(unit, (on, -off, off), [0,0,2], 1250000)\n",
    "# rv6 = generate_cluster(unit, (-on, off, -off), [0,2,0], 1000000)\n",
    "# \n",
    "# data = np.append(shuffle(rv1, rv2, rv3, rv4), shuffle(rv5, rv6), axis=1)\n",
    "\n",
    "data = reduce(lambda a,b: np.append(a, b, axis=0), [rv1, rv2, rv3, rv4])\n",
    "\n",
    "# ind_var = np.random.uniform(-1, 1, [data.shape[0], 20])\n",
    "\n",
    "# data = np.append(data, ind_var, axis=1)\n",
    "\n",
    "data = shuffle(data)\n",
    "\n",
    "# data = reduce_correlation(data, [0.75, 0.75, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]),\n array([-2.83130242, -2.7004229 , -2.56954339, -2.43866387, -2.30778436,\n        -2.17690484, -2.04602532, -1.91514581, -1.78426629, -1.65338678,\n        -1.52250726, -1.39162775, -1.26074823, -1.12986872, -0.9989892 ,\n        -0.86810968, -0.73723017, -0.60635065, -0.47547114, -0.34459162,\n        -0.21371211, -0.08283259,  0.04804692,  0.17892644,  0.30980595,\n         0.44068547,  0.57156499,  0.7024445 ,  0.83332402,  0.96420353,\n         1.09508305,  1.22596256,  1.35684208,  1.48772159,  1.61860111,\n         1.74948063,  1.88036014,  2.01123966,  2.14211917,  2.27299869,\n         2.4038782 ,  2.53475772,  2.66563723,  2.79651675,  2.92739626,\n         3.05827578,  3.1891553 ,  3.32003481,  3.45091433,  3.58179384,\n         3.71267336]),\n array([-2.98538785e+00, -2.84983180e+00, -2.71427575e+00, -2.57871970e+00,\n        -2.44316364e+00, -2.30760759e+00, -2.17205154e+00, -2.03649549e+00,\n        -1.90093944e+00, -1.76538338e+00, -1.62982733e+00, -1.49427128e+00,\n        -1.35871523e+00, -1.22315918e+00, -1.08760312e+00, -9.52047072e-01,\n        -8.16491020e-01, -6.80934968e-01, -5.45378916e-01, -4.09822864e-01,\n        -2.74266812e-01, -1.38710760e-01, -3.15470798e-03,  1.32401344e-01,\n         2.67957396e-01,  4.03513448e-01,  5.39069500e-01,  6.74625552e-01,\n         8.10181604e-01,  9.45737656e-01,  1.08129371e+00,  1.21684976e+00,\n         1.35240581e+00,  1.48796186e+00,  1.62351792e+00,  1.75907397e+00,\n         1.89463002e+00,  2.03018607e+00,  2.16574212e+00,  2.30129818e+00,\n         2.43685423e+00,  2.57241028e+00,  2.70796633e+00,  2.84352238e+00,\n         2.97907844e+00,  3.11463449e+00,  3.25019054e+00,  3.38574659e+00,\n         3.52130265e+00,  3.65685870e+00,  3.79241475e+00]),\n <matplotlib.image.AxesImage at 0x7efe675ffb00>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe6769fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist2d(data[:,0], data[:,1], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(object):\n",
    "    def __init__(self, n_input_units, n_hidden_layers, n_hidden_units, n_latent_units,\n",
    "                 learning_rate=0.005, batch_size=100, min_beta=1.0, max_beta=1.0,\n",
    "                 distribution='normal'):\n",
    "        self.n_input_units = n_input_units\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_hidden_units = n_hidden_units\n",
    "        self.n_latent_units = n_latent_units\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.min_beta = min_beta\n",
    "        self.max_beta = max_beta\n",
    "        self.distribution = distribution\n",
    "\n",
    "    class Encoder(object):\n",
    "        def __init__(self, n_hidden_layers, n_hidden_units, n_latent_units, distribution):\n",
    "            self.n_hidden_layers = n_hidden_layers\n",
    "            self.n_hidden_units = n_hidden_units\n",
    "            self.n_latent_units = n_latent_units\n",
    "            self.distribution = distribution\n",
    "\n",
    "        def init_hidden_layers(self):\n",
    "            self.hidden_layers = []\n",
    "            self.applied_hidden_layers = []\n",
    "\n",
    "        def add_hidden_layer(self, inputs):\n",
    "            self.hidden_layers.append(tf.layers.Dense(units=self.n_hidden_units, activation=tf.nn.sigmoid))\n",
    "            self.applied_hidden_layers.append(self.hidden_layers[-1].apply(inputs))\n",
    "            return self.applied_hidden_layers[-1]\n",
    "\n",
    "        def add_mu(self, inputs):\n",
    "            self.mu = tf.layers.Dense(units=self.n_latent_units)\n",
    "            self.applied_mu = self.mu.apply(inputs)\n",
    "            return self.applied_mu\n",
    "\n",
    "        def add_sigma(self, inputs):\n",
    "            if self.distribution == 'normal':\n",
    "                units = self.n_latent_units\n",
    "            elif self.distribution == 'vmf':\n",
    "                units = 1\n",
    "            else:\n",
    "                raise NotImplemented\n",
    "            self.sigma = tf.layers.Dense(units=units)\n",
    "            self.applied_sigma = self.sigma.apply(inputs)\n",
    "            return self.applied_sigma\n",
    "\n",
    "        def build(self, inputs):\n",
    "            self.init_hidden_layers()\n",
    "\n",
    "            layer = self.add_hidden_layer(inputs)\n",
    "\n",
    "            for i in range(self.n_hidden_layers - 1):\n",
    "                layer = self.add_hidden_layer(layer)\n",
    "\n",
    "            mu = self.add_mu(layer)\n",
    "            sigma = self.add_sigma(layer)\n",
    "\n",
    "            return mu, sigma\n",
    "\n",
    "        def eval(self, sess):\n",
    "            layers = [\n",
    "                sess.run([l.kernel, l.bias])\n",
    "                for l in self.hidden_layers\n",
    "            ]\n",
    "\n",
    "            mu = sess.run([self.mu.kernel, self.mu.bias])\n",
    "\n",
    "            sigma = sess.run([self.sigma.kernel, self.sigma.bias])\n",
    "\n",
    "            return layers, mu, sigma\n",
    "\n",
    "    class Decoder(object):\n",
    "        def __init__(self, n_hidden_layers, n_hidden_units, n_output_units):\n",
    "            self.n_hidden_layers = n_hidden_layers\n",
    "            self.n_hidden_units = n_hidden_units\n",
    "            self.n_output_units = n_output_units\n",
    "\n",
    "        def init_hidden_layers(self):\n",
    "            self.hidden_layers = []\n",
    "            self.applied_hidden_layers = []\n",
    "\n",
    "        def add_hidden_layer(self, inputs):\n",
    "            self.hidden_layers.append(tf.layers.Dense(units=self.n_hidden_units, activation=tf.nn.sigmoid))\n",
    "            self.applied_hidden_layers.append(self.hidden_layers[-1].apply(inputs))\n",
    "            return self.applied_hidden_layers[-1]\n",
    "\n",
    "        def add_output(self, inputs):\n",
    "            self.output = tf.layers.Dense(units=self.n_output_units)\n",
    "            self.applied_output = self.output.apply(inputs)\n",
    "            return self.applied_output\n",
    "\n",
    "        def build(self, inputs):\n",
    "            self.init_hidden_layers()\n",
    "\n",
    "            layer = self.add_hidden_layer(inputs)\n",
    "\n",
    "            for i in range(self.n_hidden_layers - 1):\n",
    "                layer = self.add_hidden_layer(layer)\n",
    "\n",
    "            output = self.add_output(layer)\n",
    "\n",
    "            return output\n",
    "\n",
    "        def eval(self, sess):\n",
    "            layers = [\n",
    "                sess.run([l.kernel, l.bias])\n",
    "                for l in self.hidden_layers\n",
    "            ]\n",
    "\n",
    "            output = sess.run([self.output.kernel, self.output.bias])\n",
    "\n",
    "            return layers, output\n",
    "\n",
    "    def sampled_z(self, mu, sigma, batch_size):\n",
    "        if self.distribution == 'normal':\n",
    "            epsilon = tf.random_normal(tf.stack([int(batch_size), self.n_latent_units]))\n",
    "            z = mu + tf.multiply(epsilon, tf.exp(0.5 * sigma))\n",
    "        elif self.distribution == 'vmf':\n",
    "            q_z = VonMisesFisher(mu, sigma)\n",
    "            z = q_z.sample()\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "\n",
    "        return z\n",
    "\n",
    "    def build_losses(self, x, output, mu, sigma):\n",
    "        feature_loss = tf.reduce_sum(tf.squared_difference(x, output), 1)\n",
    "        latent_loss = -0.5 * self.beta * tf.reduce_sum(1.0 + sigma - tf.square(mu) - tf.exp(sigma), 1)\n",
    "        loss = tf.reduce_mean(feature_loss + latent_loss)\n",
    "        return loss, feature_loss, latent_loss\n",
    "\n",
    "    def initialize_tensors(self):\n",
    "        self.x = tf.placeholder(\"float32\", [self.batch_size, self.n_input_units])\n",
    "        self.beta = tf.placeholder(\"float32\", [1, 1])\n",
    "        self.encoder = self.Encoder(self.n_hidden_layers, self.n_hidden_units, self.n_latent_units, \n",
    "                                    self.distribution)\n",
    "        mu, sigma = self.encoder.build(self.x)\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.z = self.sampled_z(self.mu, self.sigma, self.batch_size)\n",
    "        self.decoder = self.Decoder(self.n_hidden_layers, self.n_hidden_units, self.n_input_units)\n",
    "        self.output = self.decoder.build(self.z)\n",
    "        loss, feature_loss, latent_loss = self.build_losses(self.x, self.output, self.mu, self.sigma)\n",
    "        self.loss = loss\n",
    "        self.feature_loss = feature_loss\n",
    "        self.latent_loss = latent_loss\n",
    "\n",
    "    def generate_beta_values(self, data_count, epochs):\n",
    "        num_batches = int(data_count / self.batch_size)\n",
    "        total_steps = (num_batches * epochs) - epochs\n",
    "        beta_delta = self.max_beta - self.min_beta\n",
    "        log_beta_step = 5 / float(total_steps)\n",
    "        beta_values = [\n",
    "            self.min_beta + (beta_delta * (1 - math.exp(-5 + (i * log_beta_step))))\n",
    "            for i in range(total_steps)\n",
    "        ]\n",
    "        return beta_values\n",
    "\n",
    "    def train_from_rdd(self, data_rdd, epochs=1):\n",
    "        self.initialize_tensors()\n",
    "\n",
    "        data_count = data_rdd.count()\n",
    "        beta_values = self.generate_beta_values(data_count, epochs)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for epoch_index in range(epochs):\n",
    "                iterator = data_rdd.toLocalIterator()\n",
    "                batch_index = 0\n",
    "                while True:\n",
    "                    batch = np.array(list(islice(iterator, self.batch_size)))\n",
    "                    if batch.shape[0] == self.batch_size:\n",
    "                        beta = beta_values.pop(0) if len(beta_values) > 0 else self.min_beta\n",
    "                        feed_dict = {self.x: np.array(batch), self.beta: np.array([[beta]])}\n",
    "\n",
    "                        if not batch_index % 100:\n",
    "                            print(\"beta: {}\".format(beta))\n",
    "                            ls, f_ls, d_ls = sess.run([self.loss, self.feature_loss, self.latent_loss],\n",
    "                                                      feed_dict=feed_dict)\n",
    "                            print(\"loss={}, avg_feature_loss={}, avg_latent_loss={}\".format(ls, np.mean(f_ls),\n",
    "                                                                                            np.mean(d_ls)))\n",
    "                            print('running batch {} in epoch {}'.format(batch_index, epoch_index))\n",
    "                        sess.run(optimizer, feed_dict=feed_dict)\n",
    "                        batch_index += 1\n",
    "                    else:\n",
    "                        print(\"incomplete batch: {}\".format(batch.shape))\n",
    "                        break\n",
    "\n",
    "            print(\"evaluating model...\")\n",
    "            encoder_layers, eval_mu, eval_sigma = self.encoder.eval(sess)\n",
    "            decoder_layers, eval_output = self.decoder.eval(sess)\n",
    "\n",
    "        return VariationalAutoEncoderModel(encoder_layers, eval_mu, eval_sigma, decoder_layers, eval_output)\n",
    "\n",
    "    def train(self, data, visualize=False, epochs=1):\n",
    "        self.initialize_tensors()\n",
    "        \n",
    "        data_size = data.shape[0]\n",
    "        batch_size = self.batch_size\n",
    "        beta_values = self.generate_beta_values(data_size, epochs)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            i = 0\n",
    "            while (i * batch_size) < data_size:\n",
    "                batch = data[i * batch_size:(i + 1) * batch_size]\n",
    "                beta = beta_values.pop(0) if len(beta_values) > 0 else self.min_beta\n",
    "                feed_dict = {self.x: batch, self.beta: np.array([[beta]])}\n",
    "                sess.run(optimizer, feed_dict=feed_dict)\n",
    "\n",
    "                if visualize and (not i % int((data_size / batch_size) / 3) or i == int(data_size / batch_size) - 1):\n",
    "                    ls, d, f_ls, d_ls = sess.run([self.loss, self.output, self.feature_loss, self.latent_loss],\n",
    "                                                 feed_dict=feed_dict)\n",
    "                    plt.scatter(batch[:, 0], batch[:, 1])\n",
    "                    plt.show()\n",
    "                    plt.scatter(d[:, 0], d[:, 1])\n",
    "                    plt.show()\n",
    "                    print(i, ls, np.mean(f_ls), np.mean(d_ls))\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            encoder_layers, eval_mu, eval_sigma = self.encoder.eval(sess)\n",
    "            decoder_layers, eval_output = self.decoder.eval(sess)\n",
    "\n",
    "        return VariationalAutoEncoderModel(encoder_layers, eval_mu, eval_sigma, decoder_layers, eval_output)\n",
    "\n",
    "\n",
    "class VariationalAutoEncoderModel(object):\n",
    "    def __init__(self, encoder_layers, mu, sigma, decoder_layers, output):\n",
    "        self.encoder = self.EncoderModel(encoder_layers, mu, sigma)\n",
    "        self.decoder = self.DecoderModel(decoder_layers, output)\n",
    "\n",
    "    def save(self, path):\n",
    "        encoder_layers, encoder_mu, encoder_sigma = self.encoder.dump()\n",
    "        decoder_layers, decoder_output = self.decoder.dump()\n",
    "        serializable_model = (encoder_layers, encoder_mu, encoder_sigma, decoder_layers, decoder_output)\n",
    "        pickle.dump(serializable_model, open(path, 'w+'))\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder.encode(x)\n",
    "\n",
    "    def project(self, x):\n",
    "        return self.encoder.encode(x)[0]\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder.decode(x)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        return cls(*pickle.load(open(path, 'r')))\n",
    "\n",
    "    class Layer(object):\n",
    "        def __init__(self, kernel, bias, activation='linear'):\n",
    "            self.kernel = kernel\n",
    "            self.bias = bias\n",
    "            self.activation = activation\n",
    "\n",
    "        def dump(self):\n",
    "            return (self.kernel, self.bias, self.activation)\n",
    "\n",
    "        @property\n",
    "        def apply_func(self):\n",
    "            kernel, bias = self.kernel, self.bias\n",
    "\n",
    "            linear = lambda inputs: np.matmul(inputs, kernel) + bias\n",
    "\n",
    "            if self.activation == 'linear':\n",
    "                f = linear\n",
    "            elif self.activation == 'sigmoid':\n",
    "                f = lambda inputs: 1 / (1 + np.exp(-linear(inputs)))\n",
    "\n",
    "            return f\n",
    "\n",
    "        def apply(self, inputs):\n",
    "            return self.apply_func(inputs)\n",
    "\n",
    "    class EncoderModel(object):\n",
    "        def __init__(self, encoder_layers, mu, sigma):\n",
    "            self.layers = [\n",
    "                VariationalAutoEncoderModel.Layer(kernel, bias, 'sigmoid')\n",
    "                for kernel, bias in encoder_layers\n",
    "            ]\n",
    "            self.mu = VariationalAutoEncoderModel.Layer(*mu)\n",
    "            self.sigma = VariationalAutoEncoderModel.Layer(*sigma)\n",
    "\n",
    "        def dump(self):\n",
    "            encoder_layers = [l.dump()[:2] for l in self.layers]\n",
    "            encoder_mu = self.mu.dump()[:2]\n",
    "            encoder_sigma = self.sigma.dump()[:2]\n",
    "            return encoder_layers, encoder_mu, encoder_sigma\n",
    "\n",
    "        def encode(self, inputs):\n",
    "            x = inputs\n",
    "            for l in self.layers:\n",
    "                x = l.apply(x)\n",
    "            return self.mu.apply(x), self.sigma.apply(x)\n",
    "\n",
    "    class DecoderModel(object):\n",
    "        def __init__(self, decoder_layers, output):\n",
    "            self.layers = [\n",
    "                VariationalAutoEncoderModel.Layer(kernel, bias, 'sigmoid')\n",
    "                for kernel, bias in decoder_layers\n",
    "            ]\n",
    "            self.output = VariationalAutoEncoderModel.Layer(*output)\n",
    "\n",
    "        def dump(self):\n",
    "            decoder_layers = [l.dump()[:2] for l in self.layers]\n",
    "            decoder_output = self.output.dump()[:2]\n",
    "            return decoder_layers, decoder_output\n",
    "\n",
    "        def decode(self, inputs):\n",
    "            x = inputs\n",
    "            for l in self.layers:\n",
    "                x = l.apply(x)\n",
    "            return self.output.apply(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_7' with dtype float and shape [1,1]\n\t [[Node: Placeholder_7 = Placeholder[dtype=DT_FLOAT, shape=[1,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_7', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-cf6fdda5566a>\", line 3, in <module>\n    .train(data, visualize=True)\n  File \"<ipython-input-11-a3e764ca20de>\", line 199, in train\n    self.initialize_tensors()\n  File \"<ipython-input-11-a3e764ca20de>\", line 134, in initialize_tensors\n    self.beta = tf.placeholder(\"float32\", [1, 1])\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1808, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4848, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_7' with dtype float and shape [1,1]\n\t [[Node: Placeholder_7 = Placeholder[dtype=DT_FLOAT, shape=[1,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_7' with dtype float and shape [1,1]\n\t [[Node: Placeholder_7 = Placeholder[dtype=DT_FLOAT, shape=[1,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cf6fdda5566a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model = VariationalAutoEncoder(n_input_units=3, n_hidden_layers=2, n_hidden_units=9, n_latent_units=1, \n\u001b[1;32m      2\u001b[0m                                learning_rate=0.005, batch_size=50, distribution='normal')\\\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-a3e764ca20de>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, visualize, epochs)\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                     ls, d, f_ls, d_ls = sess.run([self.loss, self.output, self.feature_loss, self.latent_loss],\n\u001b[0;32m--> 218\u001b[0;31m                                                  feed_dict={self.x: batch})\n\u001b[0m\u001b[1;32m    219\u001b[0m                     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_7' with dtype float and shape [1,1]\n\t [[Node: Placeholder_7 = Placeholder[dtype=DT_FLOAT, shape=[1,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_7', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-cf6fdda5566a>\", line 3, in <module>\n    .train(data, visualize=True)\n  File \"<ipython-input-11-a3e764ca20de>\", line 199, in train\n    self.initialize_tensors()\n  File \"<ipython-input-11-a3e764ca20de>\", line 134, in initialize_tensors\n    self.beta = tf.placeholder(\"float32\", [1, 1])\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1808, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4848, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_7' with dtype float and shape [1,1]\n\t [[Node: Placeholder_7 = Placeholder[dtype=DT_FLOAT, shape=[1,1], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model = VariationalAutoEncoder(n_input_units=3, n_hidden_layers=2, n_hidden_units=9, n_latent_units=1, \n",
    "                               learning_rate=0.005, batch_size=50, distribution='normal')\\\n",
    "    .train(data, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  9.90000000e+01,   1.37000000e+03,   1.12730000e+04,\n          1.14196000e+05,   1.14187000e+05,   7.66040000e+04,\n          5.16410000e+04,   3.64460000e+04,   2.60790000e+04,\n          1.88520000e+04,   1.36100000e+04,   1.00560000e+04,\n          7.34400000e+03,   5.29900000e+03,   3.70300000e+03,\n          2.68100000e+03,   1.85200000e+03,   1.40500000e+03,\n          9.85000000e+02,   7.22000000e+02,   5.06000000e+02,\n          3.41000000e+02,   2.54000000e+02,   1.68000000e+02,\n          1.23000000e+02,   9.00000000e+01,   8.90000000e+01,\n          9.30000000e+01,   1.36000000e+02,   2.03000000e+02,\n          3.30000000e+02,   5.87000000e+02,   1.10600000e+03,\n          2.60600000e+03,   8.22900000e+03,   1.64695000e+05,\n          6.56060000e+04,   4.34900000e+03,   1.26800000e+03,\n          6.03000000e+02,   3.19000000e+02,   2.57000000e+02,\n          2.31000000e+02,   2.27000000e+02,   2.83000000e+02,\n          3.09000000e+02,   4.03000000e+02,   5.34000000e+02,\n          7.87000000e+02,   1.45500000e+03,   3.41900000e+03,\n          2.02280000e+04,   9.71800000e+04,   3.03103000e+05,\n          6.41200000e+04,   5.87100000e+03,   8.92000000e+02,\n          3.05000000e+02,   1.10000000e+02,   6.60000000e+01,\n          3.80000000e+01,   3.10000000e+01,   2.40000000e+01,\n          1.60000000e+01,   1.70000000e+01,   1.00000000e+01,\n          1.50000000e+01,   9.00000000e+00,   4.00000000e+00,\n          1.00000000e+01,   1.00000000e+01,   1.30000000e+01,\n          5.00000000e+00,   1.90000000e+01,   1.00000000e+01,\n          1.10000000e+01,   1.20000000e+01,   1.70000000e+01,\n          1.50000000e+01,   1.10000000e+01,   2.00000000e+01,\n          2.50000000e+01,   2.00000000e+01,   3.00000000e+01,\n          5.70000000e+01,   4.30000000e+01,   6.80000000e+01,\n          7.50000000e+01,   1.02000000e+02,   1.59000000e+02,\n          2.67000000e+02,   3.67000000e+02,   6.94000000e+02,\n          1.42100000e+03,   4.26100000e+03,   2.59250000e+04,\n          2.01213000e+05,   3.19434000e+05,   3.12758000e+05,\n          1.32879000e+05]),\n array([-1.5745995 , -1.54858132, -1.52256314, -1.49654496, -1.47052678,\n        -1.4445086 , -1.41849042, -1.39247225, -1.36645407, -1.34043589,\n        -1.31441771, -1.28839953, -1.26238135, -1.23636317, -1.21034499,\n        -1.18432681, -1.15830863, -1.13229045, -1.10627228, -1.0802541 ,\n        -1.05423592, -1.02821774, -1.00219956, -0.97618138, -0.9501632 ,\n        -0.92414502, -0.89812684, -0.87210866, -0.84609049, -0.82007231,\n        -0.79405413, -0.76803595, -0.74201777, -0.71599959, -0.68998141,\n        -0.66396323, -0.63794505, -0.61192687, -0.58590869, -0.55989052,\n        -0.53387234, -0.50785416, -0.48183598, -0.4558178 , -0.42979962,\n        -0.40378144, -0.37776326, -0.35174508, -0.3257269 , -0.29970872,\n        -0.27369055, -0.24767237, -0.22165419, -0.19563601, -0.16961783,\n        -0.14359965, -0.11758147, -0.09156329, -0.06554511, -0.03952693,\n        -0.01350875,  0.01250942,  0.0385276 ,  0.06454578,  0.09056396,\n         0.11658214,  0.14260032,  0.1686185 ,  0.19463668,  0.22065486,\n         0.24667304,  0.27269122,  0.29870939,  0.32472757,  0.35074575,\n         0.37676393,  0.40278211,  0.42880029,  0.45481847,  0.48083665,\n         0.50685483,  0.53287301,  0.55889119,  0.58490936,  0.61092754,\n         0.63694572,  0.6629639 ,  0.68898208,  0.71500026,  0.74101844,\n         0.76703662,  0.7930548 ,  0.81907298,  0.84509116,  0.87110933,\n         0.89712751,  0.92314569,  0.94916387,  0.97518205,  1.00120023,\n         1.02721841]),\n <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72f00b85c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.encoder.encode(data)[0], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = model.encoder.encode(data)[0]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    m = GaussianMixture(i).fit(mus)\n",
    "    results.append((i, m.score(mus), m.aic(mus), m.bic(mus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, -1.349808787495403, 6074143.5437293136, 6074168.796610862),\n (2, -0.16352232973647432, 735860.4838141345, 735923.61601800541),\n (3, 0.2106959228959403, -948115.65303173137, -948014.6415055379),\n (4, 0.63413533432107461, -2853587.0044448357, -2853448.1135963197),\n (5, 0.65035754820199487, -2926580.9669089769, -2926404.1967381383),\n (6, 0.86345505427588054, -3885513.7442414626, -3885299.0947483014),\n (7, 0.79605181388766111, -3582193.162494475, -3581940.6336789913),\n (8, 0.8646548225404691, -3890900.7014321107, -3890610.2932943045),\n (9, 0.88927691745299919, -4001694.1285384963, -4001365.8410783675)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        ..., \n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n array([-1.5826096 , -1.52876103, -1.47491246, -1.42106389, -1.36721532,\n        -1.31336675, -1.25951818, -1.20566961, -1.15182104, -1.09797247,\n        -1.0441239 , -0.99027533, -0.93642676, -0.88257819, -0.82872962,\n        -0.77488105, -0.72103248, -0.66718391, -0.61333534, -0.55948677,\n        -0.5056382 , -0.45178963, -0.39794106, -0.34409249, -0.29024392,\n        -0.23639535, -0.18254678, -0.12869821, -0.07484964, -0.02100107,\n         0.0328475 ,  0.08669607,  0.14054464,  0.19439321,  0.24824178,\n         0.30209035,  0.35593892,  0.40978749,  0.46363606,  0.51748463,\n         0.5713332 ,  0.62518177,  0.67903034,  0.73287891,  0.78672748,\n         0.84057605,  0.89442462,  0.94827319,  1.00212176,  1.05597033,\n         1.1098189 ]),\n array([-5.68882119, -5.59009498, -5.49136877, -5.39264256, -5.29391635,\n        -5.19519014, -5.09646393, -4.99773772, -4.89901151, -4.8002853 ,\n        -4.70155909, -4.60283288, -4.50410667, -4.40538046, -4.30665425,\n        -4.20792804, -4.10920183, -4.01047562, -3.91174941, -3.8130232 ,\n        -3.71429699, -3.61557078, -3.51684457, -3.41811836, -3.31939216,\n        -3.22066595, -3.12193974, -3.02321353, -2.92448732, -2.82576111,\n        -2.7270349 , -2.62830869, -2.52958248, -2.43085627, -2.33213006,\n        -2.23340385, -2.13467764, -2.03595143, -1.93722522, -1.83849901,\n        -1.7397728 , -1.64104659, -1.54232038, -1.44359417, -1.34486796,\n        -1.24614175, -1.14741554, -1.04868933, -0.94996312, -0.85123691,\n        -0.7525107 ]),\n <matplotlib.image.AxesImage at 0x7f7e55ef8dd8>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e55efc7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist2d(model.encoder.encode(data)[0].squeeze(1), model.encoder.encode(data)[1].squeeze(1), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
