{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from itertools import islice\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hyperspherical_vae.distributions import VonMisesFisher, HypersphericalUniform\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(*dfs):\n",
    "  dataset = reduce(lambda a,b: np.append(a, b, axis=0), dfs)\n",
    "  permutation = np.random.permutation(dataset.shape[0])\n",
    "  shuffled = dataset[permutation]\n",
    "  return shuffled\n",
    "\n",
    "\n",
    "unit = 0.15\n",
    "\n",
    "on = unit * 0.1\n",
    "off = unit * 0.00\n",
    "\n",
    "\n",
    "def generate_cluster(unit, cross_cov, mu, count):\n",
    "    mu = np.array(mu)\n",
    "    sigma_1, sigma_2, sigma_3 = unit, unit, unit\n",
    "    sigma_1_2, sigma_1_3, sigma_2_3 = cross_cov\n",
    "    cov = np.array([\n",
    "      [sigma_1, sigma_1_2, sigma_1_3],\n",
    "      [sigma_1_2, sigma_2, sigma_2_3],\n",
    "      [sigma_1_3, sigma_2_3, sigma_3]\n",
    "    ])\n",
    "    ds = np.random.multivariate_normal(mu, cov, count)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def reduce_correlation(ds, noise):\n",
    "    count = ds.shape[0]\n",
    "    ds_t = ds.T\n",
    "    for i, x in enumerate(noise):\n",
    "        num = int(count*x)\n",
    "        ds_t[i].put(np.random.choice(count, num, replace=False), np.random.choice(ds.T[i], num))\n",
    "    return ds_t.T\n",
    "\n",
    "\n",
    "rv1 = generate_cluster(unit, (on, -off, off), [2,0,0], 250000) \n",
    "rv2 = generate_cluster(unit, (on, off, -off), [0,0,2], 500000)\n",
    "rv3 = generate_cluster(unit, (-on, off, off), [0,2,0], 500000)\n",
    "rv4 = generate_cluster(unit, (-on, -off, -off), [-1,-1,-1], 1000000)\n",
    "\n",
    "# rv5 = generate_cluster(unit, (on, -off, off), [0,0,2], 1250000)\n",
    "# rv6 = generate_cluster(unit, (-on, off, -off), [0,2,0], 1000000)\n",
    "# \n",
    "# data = np.append(shuffle(rv1, rv2, rv3, rv4), shuffle(rv5, rv6), axis=1)\n",
    "\n",
    "data = reduce(lambda a,b: np.append(a, b, axis=0), [rv1, rv2, rv3, rv4])\n",
    "\n",
    "# ind_var = np.random.uniform(-1, 1, [data.shape[0], 20])\n",
    "\n",
    "# data = np.append(data, ind_var, axis=1)\n",
    "\n",
    "data = shuffle(data)\n",
    "\n",
    "# data = reduce_correlation(data, [0.75, 0.75, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]),\n array([-2.83249943, -2.69914232, -2.56578522, -2.43242811, -2.29907101,\n        -2.16571391, -2.0323568 , -1.8989997 , -1.76564259, -1.63228549,\n        -1.49892839, -1.36557128, -1.23221418, -1.09885707, -0.96549997,\n        -0.83214287, -0.69878576, -0.56542866, -0.43207155, -0.29871445,\n        -0.16535735, -0.03200024,  0.10135686,  0.23471397,  0.36807107,\n         0.50142817,  0.63478528,  0.76814238,  0.90149949,  1.03485659,\n         1.16821369,  1.3015708 ,  1.4349279 ,  1.56828501,  1.70164211,\n         1.83499922,  1.96835632,  2.10171342,  2.23507053,  2.36842763,\n         2.50178474,  2.63514184,  2.76849894,  2.90185605,  3.03521315,\n         3.16857026,  3.30192736,  3.43528446,  3.56864157,  3.70199867,\n         3.83535578]),\n array([-2.94668095e+00, -2.81274363e+00, -2.67880631e+00, -2.54486899e+00,\n        -2.41093167e+00, -2.27699435e+00, -2.14305703e+00, -2.00911971e+00,\n        -1.87518239e+00, -1.74124507e+00, -1.60730775e+00, -1.47337043e+00,\n        -1.33943311e+00, -1.20549579e+00, -1.07155847e+00, -9.37621152e-01,\n        -8.03683832e-01, -6.69746512e-01, -5.35809193e-01, -4.01871873e-01,\n        -2.67934553e-01, -1.33997233e-01, -5.99137457e-05,  1.33877406e-01,\n         2.67814726e-01,  4.01752045e-01,  5.35689365e-01,  6.69626685e-01,\n         8.03564005e-01,  9.37501324e-01,  1.07143864e+00,  1.20537596e+00,\n         1.33931328e+00,  1.47325060e+00,  1.60718792e+00,  1.74112524e+00,\n         1.87506256e+00,  2.00899988e+00,  2.14293720e+00,  2.27687452e+00,\n         2.41081184e+00,  2.54474916e+00,  2.67868648e+00,  2.81262380e+00,\n         2.94656112e+00,  3.08049844e+00,  3.21443576e+00,  3.34837308e+00,\n         3.48231040e+00,  3.61624772e+00,  3.75018504e+00]),\n <matplotlib.image.AxesImage at 0x7f050be6c2e8>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f050bdc3b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist2d(data[:,0], data[:,1], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(object):\n",
    "    def __init__(self, n_input_units, n_hidden_layers, n_hidden_units, n_latent_units,\n",
    "                 learning_rate=0.005, batch_size=100, min_beta=1.0, max_beta=1.0,\n",
    "                 distribution='normal'):\n",
    "        self.n_input_units = n_input_units\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_hidden_units = n_hidden_units\n",
    "        self.n_latent_units = n_latent_units\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.min_beta = min_beta\n",
    "        self.max_beta = max_beta\n",
    "        self.distribution = distribution\n",
    "\n",
    "    class Encoder(object):\n",
    "        def __init__(self, n_hidden_layers, n_hidden_units, n_latent_units, distribution):\n",
    "            self.n_hidden_layers = n_hidden_layers\n",
    "            self.n_hidden_units = n_hidden_units\n",
    "            self.n_latent_units = n_latent_units\n",
    "            self.distribution = distribution\n",
    "\n",
    "        def init_hidden_layers(self):\n",
    "            self.hidden_layers = []\n",
    "            self.applied_hidden_layers = []\n",
    "\n",
    "        def add_hidden_layer(self, inputs):\n",
    "            self.hidden_layers.append(tf.layers.Dense(units=self.n_hidden_units, activation=tf.nn.sigmoid))\n",
    "            self.applied_hidden_layers.append(self.hidden_layers[-1].apply(inputs))\n",
    "            return self.applied_hidden_layers[-1]\n",
    "\n",
    "        def add_mu(self, inputs):\n",
    "            if self.distribution == 'normal':\n",
    "                self.mu = tf.layers.Dense(units=self.n_latent_units)\n",
    "            elif self.distribution == 'vmf':\n",
    "                self.mu = tf.layers.Dense(units=self.n_latent_units + 1, \n",
    "                                          activation=lambda x: tf.nn.l2_normalize(x, axis=-1))\n",
    "            else:\n",
    "                raise NotImplemented\n",
    "                \n",
    "            self.applied_mu = self.mu.apply(inputs)\n",
    "            return self.applied_mu\n",
    "\n",
    "        def add_sigma(self, inputs):\n",
    "            if self.distribution == 'normal':\n",
    "                self.sigma = tf.layers.Dense(units=self.n_latent_units)\n",
    "                self.applied_sigma = self.sigma.apply(inputs)\n",
    "            elif self.distribution == 'vmf':\n",
    "                self.sigma = tf.layers.Dense(units=1, activation=tf.nn.softplus)\n",
    "                self.applied_sigma = self.sigma.apply(inputs) + 1\n",
    "            else:\n",
    "                raise NotImplemented\n",
    "            return self.applied_sigma\n",
    "\n",
    "        def build(self, inputs):\n",
    "            self.init_hidden_layers()\n",
    "\n",
    "            layer = self.add_hidden_layer(inputs)\n",
    "\n",
    "            for i in range(self.n_hidden_layers - 1):\n",
    "                layer = self.add_hidden_layer(layer)\n",
    "\n",
    "            mu = self.add_mu(layer)\n",
    "            sigma = self.add_sigma(layer)\n",
    "\n",
    "            return mu, sigma\n",
    "\n",
    "        def eval(self, sess):\n",
    "            layers = [\n",
    "                sess.run([l.kernel, l.bias])\n",
    "                for l in self.hidden_layers\n",
    "            ]\n",
    "\n",
    "            mu = sess.run([self.mu.kernel, self.mu.bias])\n",
    "\n",
    "            sigma = sess.run([self.sigma.kernel, self.sigma.bias])\n",
    "\n",
    "            return layers, mu, sigma\n",
    "\n",
    "    class Decoder(object):\n",
    "        def __init__(self, n_hidden_layers, n_hidden_units, n_output_units):\n",
    "            self.n_hidden_layers = n_hidden_layers\n",
    "            self.n_hidden_units = n_hidden_units\n",
    "            self.n_output_units = n_output_units\n",
    "\n",
    "        def init_hidden_layers(self):\n",
    "            self.hidden_layers = []\n",
    "            self.applied_hidden_layers = []\n",
    "\n",
    "        def add_hidden_layer(self, inputs):\n",
    "            self.hidden_layers.append(tf.layers.Dense(units=self.n_hidden_units, activation=tf.nn.sigmoid))\n",
    "            self.applied_hidden_layers.append(self.hidden_layers[-1].apply(inputs))\n",
    "            return self.applied_hidden_layers[-1]\n",
    "\n",
    "        def add_output(self, inputs):\n",
    "            self.output = tf.layers.Dense(units=self.n_output_units)\n",
    "            self.applied_output = self.output.apply(inputs)\n",
    "            return self.applied_output\n",
    "\n",
    "        def build(self, inputs):\n",
    "            self.init_hidden_layers()\n",
    "\n",
    "            layer = self.add_hidden_layer(inputs)\n",
    "\n",
    "            for i in range(self.n_hidden_layers - 1):\n",
    "                layer = self.add_hidden_layer(layer)\n",
    "\n",
    "            output = self.add_output(layer)\n",
    "\n",
    "            return output\n",
    "\n",
    "        def eval(self, sess):\n",
    "            layers = [\n",
    "                sess.run([l.kernel, l.bias])\n",
    "                for l in self.hidden_layers\n",
    "            ]\n",
    "\n",
    "            output = sess.run([self.output.kernel, self.output.bias])\n",
    "\n",
    "            return layers, output\n",
    "\n",
    "    def sampled_z(self, mu, sigma, batch_size):\n",
    "        if self.distribution == 'normal':\n",
    "            epsilon = tf.random_normal(tf.stack([int(batch_size), self.n_latent_units]))\n",
    "            z = mu + tf.multiply(epsilon, tf.exp(0.5 * sigma))\n",
    "            loss = tf.reduce_mean(-0.5 * self.beta * tf.reduce_sum(1.0 + sigma - tf.square(mu) - tf.exp(sigma), 1))\n",
    "        elif self.distribution == 'vmf':\n",
    "            self.q_z = VonMisesFisher(mu, sigma, validate_args=True, allow_nan_stats=False)\n",
    "            z = self.q_z.sample()\n",
    "            self.p_z = HypersphericalUniform(self.n_latent_units, validate_args=True, allow_nan_stats=False)\n",
    "            loss = tf.reduce_mean(-self.q_z.kl_divergence(self.p_z))\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "\n",
    "        return z, loss\n",
    "\n",
    "    def build_feature_loss(self, x, output):\n",
    "        return tf.reduce_mean(tf.reduce_sum(tf.squared_difference(x, output), 1))\n",
    "\n",
    "    def initialize_tensors(self):\n",
    "        self.x = tf.placeholder(\"float32\", [self.batch_size, self.n_input_units])\n",
    "        self.beta = tf.placeholder(\"float32\", [1, 1])\n",
    "        self.encoder = self.Encoder(self.n_hidden_layers, self.n_hidden_units, self.n_latent_units, \n",
    "                                    self.distribution)\n",
    "        mu, sigma = self.encoder.build(self.x)\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        z, latent_loss = self.sampled_z(self.mu, self.sigma, self.batch_size)\n",
    "        self.z = z\n",
    "        self.latent_loss = latent_loss\n",
    "        \n",
    "        self.decoder = self.Decoder(self.n_hidden_layers, self.n_hidden_units, self.n_input_units)\n",
    "        self.output = self.decoder.build(self.z)\n",
    "        \n",
    "        self.feature_loss = self.build_feature_loss(self.x, self.output)\n",
    "        self.loss = self.feature_loss + self.latent_loss\n",
    "        \n",
    "\n",
    "    def generate_beta_values(self, data_count, epochs):\n",
    "        num_batches = int(data_count / self.batch_size)\n",
    "        total_steps = (num_batches * epochs) - epochs\n",
    "        beta_delta = self.max_beta - self.min_beta\n",
    "        log_beta_step = 5 / float(total_steps)\n",
    "        beta_values = [\n",
    "            self.min_beta + (beta_delta * (1 - math.exp(-5 + (i * log_beta_step))))\n",
    "            for i in range(total_steps)\n",
    "        ]\n",
    "        return beta_values\n",
    "\n",
    "    def train_from_rdd(self, data_rdd, epochs=1):\n",
    "        self.initialize_tensors()\n",
    "\n",
    "        data_count = data_rdd.count()\n",
    "        beta_values = self.generate_beta_values(data_count, epochs)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for epoch_index in range(epochs):\n",
    "                iterator = data_rdd.toLocalIterator()\n",
    "                batch_index = 0\n",
    "                while True:\n",
    "                    batch = np.array(list(islice(iterator, self.batch_size)))\n",
    "                    if batch.shape[0] == self.batch_size:\n",
    "                        beta = beta_values.pop(0) if len(beta_values) > 0 else self.min_beta\n",
    "                        feed_dict = {self.x: np.array(batch), self.beta: np.array([[beta]])}\n",
    "\n",
    "                        if not batch_index % 1000:\n",
    "                            print(\"beta: {}\".format(beta))\n",
    "                            ls, f_ls, d_ls = sess.run([self.loss, self.feature_loss, self.latent_loss],\n",
    "                                                      feed_dict=feed_dict)\n",
    "                            print(\"loss={}, avg_feature_loss={}, avg_latent_loss={}\".format(ls, np.mean(f_ls),\n",
    "                                                                                            np.mean(d_ls)))\n",
    "                            print('running batch {} in epoch {}'.format(batch_index, epoch_index))\n",
    "                        sess.run(optimizer, feed_dict=feed_dict)\n",
    "                        batch_index += 1\n",
    "                    else:\n",
    "                        print(\"incomplete batch: {}\".format(batch.shape))\n",
    "                        break\n",
    "\n",
    "            print(\"evaluating model...\")\n",
    "            encoder_layers, eval_mu, eval_sigma = self.encoder.eval(sess)\n",
    "            decoder_layers, eval_output = self.decoder.eval(sess)\n",
    "\n",
    "        return VariationalAutoEncoderModel(encoder_layers, eval_mu, eval_sigma, decoder_layers, eval_output)\n",
    "\n",
    "    def train(self, data, visualize=False, epochs=1):\n",
    "        self.initialize_tensors()\n",
    "        \n",
    "        data_size = data.shape[0]\n",
    "        batch_size = self.batch_size\n",
    "        beta_values = self.generate_beta_values(data_size, epochs)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            i = 0\n",
    "            while (i * batch_size) < data_size:\n",
    "                batch = data[i * batch_size:(i + 1) * batch_size]\n",
    "                beta = beta_values.pop(0) if len(beta_values) > 0 else self.min_beta\n",
    "                feed_dict = {self.x: batch, self.beta: np.array([[beta]])}\n",
    "                sess.run(optimizer, feed_dict=feed_dict)\n",
    "                if visualize and (not i % int((data_size / batch_size) / 3) or i == int(data_size / batch_size) - 1):\n",
    "                    ls, d, f_ls, d_ls = sess.run([self.loss, self.output, self.feature_loss, self.latent_loss],\n",
    "                                                 feed_dict=feed_dict)\n",
    "                    plt.scatter(batch[:, 0], batch[:, 1])\n",
    "                    plt.show()\n",
    "                    plt.scatter(d[:, 0], d[:, 1])\n",
    "                    plt.show()\n",
    "                    print(i, ls, np.mean(f_ls), np.mean(d_ls))\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            encoder_layers, eval_mu, eval_sigma = self.encoder.eval(sess)\n",
    "            decoder_layers, eval_output = self.decoder.eval(sess)\n",
    "\n",
    "        return VariationalAutoEncoderModel(encoder_layers, eval_mu, eval_sigma, decoder_layers, eval_output)\n",
    "\n",
    "\n",
    "class VariationalAutoEncoderModel(object):\n",
    "    def __init__(self, encoder_layers, mu, sigma, decoder_layers, output):\n",
    "        self.encoder = self.EncoderModel(encoder_layers, mu, sigma)\n",
    "        self.decoder = self.DecoderModel(decoder_layers, output)\n",
    "\n",
    "    def save(self, path):\n",
    "        encoder_layers, encoder_mu, encoder_sigma = self.encoder.dump()\n",
    "        decoder_layers, decoder_output = self.decoder.dump()\n",
    "        serializable_model = (encoder_layers, encoder_mu, encoder_sigma, decoder_layers, decoder_output)\n",
    "        pickle.dump(serializable_model, open(path, 'w+'))\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder.encode(x)\n",
    "\n",
    "    def project(self, x):\n",
    "        return self.encoder.encode(x)[0]\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder.decode(x)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        return cls(*pickle.load(open(path, 'r')))\n",
    "\n",
    "    class Layer(object):\n",
    "        def __init__(self, kernel, bias, activation='linear'):\n",
    "            self.kernel = kernel\n",
    "            self.bias = bias\n",
    "            self.activation = activation\n",
    "\n",
    "        def dump(self):\n",
    "            return (self.kernel, self.bias, self.activation)\n",
    "\n",
    "        @property\n",
    "        def apply_func(self):\n",
    "            kernel, bias = self.kernel, self.bias\n",
    "\n",
    "            linear = lambda inputs: np.matmul(inputs, kernel) + bias\n",
    "\n",
    "            if self.activation == 'linear':\n",
    "                f = linear\n",
    "            elif self.activation == 'sigmoid':\n",
    "                f = lambda inputs: 1 / (1 + np.exp(-linear(inputs)))\n",
    "\n",
    "            return f\n",
    "\n",
    "        def apply(self, inputs):\n",
    "            return self.apply_func(inputs)\n",
    "\n",
    "    class EncoderModel(object):\n",
    "        def __init__(self, encoder_layers, mu, sigma):\n",
    "            self.layers = [\n",
    "                VariationalAutoEncoderModel.Layer(kernel, bias, 'sigmoid')\n",
    "                for kernel, bias in encoder_layers\n",
    "            ]\n",
    "            self.mu = VariationalAutoEncoderModel.Layer(*mu)\n",
    "            self.sigma = VariationalAutoEncoderModel.Layer(*sigma)\n",
    "\n",
    "        def dump(self):\n",
    "            encoder_layers = [l.dump()[:2] for l in self.layers]\n",
    "            encoder_mu = self.mu.dump()[:2]\n",
    "            encoder_sigma = self.sigma.dump()[:2]\n",
    "            return encoder_layers, encoder_mu, encoder_sigma\n",
    "\n",
    "        def encode(self, inputs):\n",
    "            x = inputs\n",
    "            for l in self.layers:\n",
    "                x = l.apply(x)\n",
    "            return self.mu.apply(x), self.sigma.apply(x)\n",
    "\n",
    "    class DecoderModel(object):\n",
    "        def __init__(self, decoder_layers, output):\n",
    "            self.layers = [\n",
    "                VariationalAutoEncoderModel.Layer(kernel, bias, 'sigmoid')\n",
    "                for kernel, bias in decoder_layers\n",
    "            ]\n",
    "            self.output = VariationalAutoEncoderModel.Layer(*output)\n",
    "\n",
    "        def dump(self):\n",
    "            decoder_layers = [l.dump()[:2] for l in self.layers]\n",
    "            decoder_output = self.output.dump()[:2]\n",
    "            return decoder_layers, decoder_output\n",
    "\n",
    "        def decode(self, inputs):\n",
    "            x = inputs\n",
    "            for l in self.layers:\n",
    "                x = l.apply(x)\n",
    "            return self.output.apply(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.9933294324709053\nloss=4.90695333480835, avg_feature_loss=4.291430473327637, avg_latent_loss=0.6155229210853577\nrunning batch 0 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.991669387004781\nloss=3.109652519226074, avg_feature_loss=2.3707802295684814, avg_latent_loss=0.7388723492622375\nrunning batch 1000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.989596220625394\nloss=2.867354154586792, avg_feature_loss=2.0870132446289062, avg_latent_loss=0.7803409099578857\nrunning batch 2000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.9870071235649049\nloss=2.3265438079833984, avg_feature_loss=1.2379647493362427, avg_latent_loss=1.0885789394378662\nrunning batch 3000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.9837737006928752\nloss=2.040351390838623, avg_feature_loss=0.9182459115982056, avg_latent_loss=1.122105598449707\nrunning batch 4000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.9797356043121276\nloss=2.2725419998168945, avg_feature_loss=0.8787100315093994, avg_latent_loss=1.3938319683074951\nrunning batch 5000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.9746925824045195\nloss=2.079235553741455, avg_feature_loss=0.7968091368675232, avg_latent_loss=1.2824264764785767\nrunning batch 6000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.9683945479935862\nloss=2.049178123474121, avg_feature_loss=0.684943675994873, avg_latent_loss=1.364234447479248\nrunning batch 7000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.9605291771568142\nloss=2.1052303314208984, avg_feature_loss=0.8664880394935608, avg_latent_loss=1.2387423515319824\nrunning batch 8000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.9507064206643211\nloss=1.9485137462615967, avg_feature_loss=0.6675841808319092, avg_latent_loss=1.2809295654296875\nrunning batch 9000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.9384391611652869\nloss=2.0060198307037354, avg_feature_loss=0.6829290986061096, avg_latent_loss=1.3230907917022705\nrunning batch 10000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.9231190566985162\nloss=1.7532199621200562, avg_feature_loss=0.5314334630966187, avg_latent_loss=1.2217864990234375\nrunning batch 11000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.9039863725899553\nloss=2.0592494010925293, avg_feature_loss=0.7125407457351685, avg_latent_loss=1.3467086553573608\nrunning batch 12000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.8800923056799046\nloss=1.930182695388794, avg_feature_loss=0.6761106252670288, avg_latent_loss=1.2540720701217651\nrunning batch 13000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.8502519325120586\nloss=1.7397935390472412, avg_feature_loss=0.5496420860290527, avg_latent_loss=1.1901514530181885\nrunning batch 14000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.8129854481522215\nloss=1.724955677986145, avg_feature_loss=0.49337342381477356, avg_latent_loss=1.2315822839736938\nrunning batch 15000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.766444781628706\nloss=1.643485426902771, avg_feature_loss=0.594866156578064, avg_latent_loss=1.048619270324707\nrunning batch 16000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.7083219488028798\nloss=1.6524548530578613, avg_feature_loss=0.57793790102005, avg_latent_loss=1.074517011642456\nrunning batch 17000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.6357345978247412\nloss=1.6136823892593384, avg_feature_loss=0.6635584235191345, avg_latent_loss=0.9501239657402039\nrunning batch 18000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.5450830712927733\nloss=1.3491926193237305, avg_feature_loss=0.48216789960861206, avg_latent_loss=0.8670246601104736\nrunning batch 19000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.431871896730817\nloss=1.1902421712875366, avg_feature_loss=0.532715380191803, avg_latent_loss=0.6575267910957336\nrunning batch 20000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.29048685297010346\nloss=0.9488694667816162, avg_feature_loss=0.47039616107940674, avg_latent_loss=0.4784733057022095\nrunning batch 21000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 0.11391655700272756\nloss=0.6356500387191772, avg_feature_loss=0.4235582649707794, avg_latent_loss=0.21209180355072021\nrunning batch 22000 in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incomplete batch: (0,)\nevaluating model...\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(data)\n",
    "\n",
    "model = VariationalAutoEncoder(n_input_units=data.shape[1], n_hidden_layers=2, \n",
    "                               n_hidden_units=9, n_latent_units=1, \n",
    "                               learning_rate=0.005, batch_size=100, \n",
    "                               min_beta=0.01, max_beta=1, distribution='normal')\\\n",
    "    .train_from_rdd(rdd, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VariationalAutoEncoder(n_input_units=data.shape[1], n_hidden_layers=2, \n",
    "                               n_hidden_units=9, n_latent_units=1, \n",
    "                               learning_rate=0.005, batch_size=100, \n",
    "                               min_beta=1, max_beta=1, distribution='vmf')\\\n",
    "    .train(data, epochs=1, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.97880e+04, 5.68307e+05, 2.29960e+05, 8.67370e+04, 3.90430e+04,\n        1.93480e+04, 1.04240e+04, 5.79400e+03, 3.49300e+03, 2.14500e+03,\n        1.35400e+03, 8.87000e+02, 6.33000e+02, 4.47000e+02, 3.61000e+02,\n        2.42000e+02, 1.91000e+02, 1.51000e+02, 1.43000e+02, 8.60000e+01,\n        7.00000e+01, 5.40000e+01, 5.90000e+01, 3.70000e+01, 3.90000e+01,\n        3.60000e+01, 2.90000e+01, 2.10000e+01, 2.40000e+01, 2.50000e+01,\n        1.80000e+01, 2.00000e+01, 1.60000e+01, 1.10000e+01, 1.90000e+01,\n        1.40000e+01, 1.60000e+01, 3.10000e+01, 3.70000e+01, 5.40000e+01,\n        9.50000e+01, 1.97000e+02, 3.94000e+02, 1.48700e+03, 6.91400e+03,\n        2.93660e+04, 8.61380e+04, 1.73057e+05, 1.75687e+05, 1.65230e+04,\n        4.50500e+03, 2.08900e+03, 1.14500e+03, 7.00000e+02, 4.70000e+02,\n        3.34000e+02, 3.05000e+02, 2.88000e+02, 3.15000e+02, 4.33000e+02,\n        6.38000e+02, 1.13600e+03, 2.20400e+03, 5.52300e+03, 2.07570e+04,\n        1.93920e+05, 2.05630e+04, 3.01400e+03, 9.92000e+02, 4.10000e+02,\n        2.02000e+02, 1.24000e+02, 1.13000e+02, 1.09000e+02, 1.37000e+02,\n        1.86000e+02, 2.79000e+02, 3.20000e+02, 4.63000e+02, 6.08000e+02,\n        8.57000e+02, 1.07100e+03, 1.42500e+03, 1.89100e+03, 2.43900e+03,\n        3.11400e+03, 3.96000e+03, 4.97500e+03, 6.30000e+03, 8.02000e+03,\n        1.01910e+04, 1.25750e+04, 1.63110e+04, 2.13470e+04, 2.86240e+04,\n        3.91610e+04, 5.48800e+04, 8.07470e+04, 1.18632e+05, 8.11760e+04]),\n array([-1.058483  , -1.0330006 , -1.00751821, -0.98203581, -0.95655341,\n        -0.93107101, -0.90558862, -0.88010622, -0.85462382, -0.82914143,\n        -0.80365903, -0.77817663, -0.75269423, -0.72721184, -0.70172944,\n        -0.67624704, -0.65076465, -0.62528225, -0.59979985, -0.57431745,\n        -0.54883506, -0.52335266, -0.49787026, -0.47238787, -0.44690547,\n        -0.42142307, -0.39594067, -0.37045828, -0.34497588, -0.31949348,\n        -0.29401109, -0.26852869, -0.24304629, -0.21756389, -0.1920815 ,\n        -0.1665991 , -0.1411167 , -0.1156343 , -0.09015191, -0.06466951,\n        -0.03918711, -0.01370472,  0.01177768,  0.03726008,  0.06274248,\n         0.08822487,  0.11370727,  0.13918967,  0.16467206,  0.19015446,\n         0.21563686,  0.24111926,  0.26660165,  0.29208405,  0.31756645,\n         0.34304884,  0.36853124,  0.39401364,  0.41949604,  0.44497843,\n         0.47046083,  0.49594323,  0.52142562,  0.54690802,  0.57239042,\n         0.59787282,  0.62335521,  0.64883761,  0.67432001,  0.6998024 ,\n         0.7252848 ,  0.7507672 ,  0.7762496 ,  0.80173199,  0.82721439,\n         0.85269679,  0.87817918,  0.90366158,  0.92914398,  0.95462638,\n         0.98010877,  1.00559117,  1.03107357,  1.05655596,  1.08203836,\n         1.10752076,  1.13300316,  1.15848555,  1.18396795,  1.20945035,\n         1.23493274,  1.26041514,  1.28589754,  1.31137994,  1.33686233,\n         1.36234473,  1.38782713,  1.41330953,  1.43879192,  1.46427432,\n         1.48975672]),\n <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff562cf9828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.encoder.encode(data)[0], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = model.encoder.encode(data)[0]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    m = GaussianMixture(i).fit(mus)\n",
    "    results.append((i, m.score(mus), m.aic(mus), m.bic(mus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, -1.349808787495403, 6074143.5437293136, 6074168.796610862),\n (2, -0.16352232973647432, 735860.4838141345, 735923.61601800541),\n (3, 0.2106959228959403, -948115.65303173137, -948014.6415055379),\n (4, 0.63413533432107461, -2853587.0044448357, -2853448.1135963197),\n (5, 0.65035754820199487, -2926580.9669089769, -2926404.1967381383),\n (6, 0.86345505427588054, -3885513.7442414626, -3885299.0947483014),\n (7, 0.79605181388766111, -3582193.162494475, -3581940.6336789913),\n (8, 0.8646548225404691, -3890900.7014321107, -3890610.2932943045),\n (9, 0.88927691745299919, -4001694.1285384963, -4001365.8410783675)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        ..., \n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n array([-1.5826096 , -1.52876103, -1.47491246, -1.42106389, -1.36721532,\n        -1.31336675, -1.25951818, -1.20566961, -1.15182104, -1.09797247,\n        -1.0441239 , -0.99027533, -0.93642676, -0.88257819, -0.82872962,\n        -0.77488105, -0.72103248, -0.66718391, -0.61333534, -0.55948677,\n        -0.5056382 , -0.45178963, -0.39794106, -0.34409249, -0.29024392,\n        -0.23639535, -0.18254678, -0.12869821, -0.07484964, -0.02100107,\n         0.0328475 ,  0.08669607,  0.14054464,  0.19439321,  0.24824178,\n         0.30209035,  0.35593892,  0.40978749,  0.46363606,  0.51748463,\n         0.5713332 ,  0.62518177,  0.67903034,  0.73287891,  0.78672748,\n         0.84057605,  0.89442462,  0.94827319,  1.00212176,  1.05597033,\n         1.1098189 ]),\n array([-5.68882119, -5.59009498, -5.49136877, -5.39264256, -5.29391635,\n        -5.19519014, -5.09646393, -4.99773772, -4.89901151, -4.8002853 ,\n        -4.70155909, -4.60283288, -4.50410667, -4.40538046, -4.30665425,\n        -4.20792804, -4.10920183, -4.01047562, -3.91174941, -3.8130232 ,\n        -3.71429699, -3.61557078, -3.51684457, -3.41811836, -3.31939216,\n        -3.22066595, -3.12193974, -3.02321353, -2.92448732, -2.82576111,\n        -2.7270349 , -2.62830869, -2.52958248, -2.43085627, -2.33213006,\n        -2.23340385, -2.13467764, -2.03595143, -1.93722522, -1.83849901,\n        -1.7397728 , -1.64104659, -1.54232038, -1.44359417, -1.34486796,\n        -1.24614175, -1.14741554, -1.04868933, -0.94996312, -0.85123691,\n        -0.7525107 ]),\n <matplotlib.image.AxesImage at 0x7f7e55ef8dd8>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e55efc7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist2d(model.encoder.encode(data)[0].squeeze(1), model.encoder.encode(data)[1].squeeze(1), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
